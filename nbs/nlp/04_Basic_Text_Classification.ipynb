{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882b48b6-1ff2-4b1f-9a50-53869c5a102a",
   "metadata": {},
   "source": [
    "# Mục Đích\n",
    "> Bài này được viết ra nhằm tổng hợp lại một vài kiến tức cơ bản của text classification như sentiment analysis (phân loại cảm xúc) hay phân loại câu hỏi... Bài này sẽ tổng hợp các kiến thức của các bài trước hoặc bổ sung kiến thức mới về NLP.\n",
    "> Bài này được viết dựa trên nội dung của bài [Basic text classification](https://www.tensorflow.org/tutorials/keras/text_classification) do team Tensorflow thực hiện. Có rất nhiều bài khác nhau ở đây, chúng ta cũng có thể sử dụng nguồn này làm tài liệu luyện thi Tensorflow Developer Certificate được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5432ec1-a8d7-4bd0-9f74-81b6319c746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp nlp.basic_text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c71ca5-8d4a-4763-a1f7-806a8fa50571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os, re, shutil, string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba175a46-2f34-4a2b-ae07-3addd027a848",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "> Chúng ta sẽ sử dụng dữ liệu IMBD kinh điển cho phân loại cảm xúc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc11ea-cebf-4bdc-a65c-1a8eb0f7598e",
   "metadata": {},
   "source": [
    "## Download dữ liệu\n",
    "> Sử dụng phương thức get_file của keras.utils để download dữ liệu từ url về:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345af6d6-2df1-48c7-9ce1-c923e6145015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muntar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmd5_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhash_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0marchive_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Downloads a file from a URL if it not already in the cache.\n",
       "\n",
       "By default the file at the url `origin` is downloaded to the\n",
       "cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n",
       "and given the filename `fname`. The final location of a file\n",
       "`example.txt` would therefore be `~/.keras/datasets/example.txt`.\n",
       "\n",
       "Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n",
       "Passing a hash will verify the file after download. The command line\n",
       "programs `shasum` and `sha256sum` can compute the hash.\n",
       "\n",
       "Example:\n",
       "\n",
       "```python\n",
       "path_to_downloaded_file = tf.keras.utils.get_file(\n",
       "    \"flower_photos\",\n",
       "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\",\n",
       "    untar=True)\n",
       "```\n",
       "\n",
       "Arguments:\n",
       "    fname: Name of the file. If an absolute path `/path/to/file.txt` is\n",
       "        specified the file will be saved at that location.\n",
       "    origin: Original URL of the file.\n",
       "    untar: Deprecated in favor of `extract` argument.\n",
       "        boolean, whether the file should be decompressed\n",
       "    md5_hash: Deprecated in favor of `file_hash` argument.\n",
       "        md5 hash of the file for verification\n",
       "    file_hash: The expected hash string of the file after download.\n",
       "        The sha256 and md5 hash algorithms are both supported.\n",
       "    cache_subdir: Subdirectory under the Keras cache dir where the file is\n",
       "        saved. If an absolute path `/path/to/folder` is\n",
       "        specified the file will be saved at that location.\n",
       "    hash_algorithm: Select the hash algorithm to verify the file.\n",
       "        options are `'md5'`, `'sha256'`, and `'auto'`.\n",
       "        The default 'auto' detects the hash algorithm in use.\n",
       "    extract: True tries extracting the file as an Archive, like tar or zip.\n",
       "    archive_format: Archive format to try for extracting the file.\n",
       "        Options are `'auto'`, `'tar'`, `'zip'`, and `None`.\n",
       "        `'tar'` includes tar, tar.gz, and tar.bz files.\n",
       "        The default `'auto'` corresponds to `['tar', 'zip']`.\n",
       "        None or an empty list will return no matches found.\n",
       "    cache_dir: Location to store cached files, when None it\n",
       "        defaults to the default directory `~/.keras/`.\n",
       "\n",
       "Returns:\n",
       "    Path to the downloaded file\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "?keras.utils.get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f1e6a-cff8-4645-8440-9eca15414e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Download dữ liệu từ url về path:\n",
    "path = '/home/ddpham/git/TFExam/data/'\n",
    "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "dataset = keras.utils.get_file('aclImdb_v1', origin=url, untar=True, cache_dir=path, cache_subdir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e664c-1f59-4c6f-ad54-be5bd0003399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Tạo lại path:\n",
    "path = os.path.join(os.path.dirname(dataset), 'aclImdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5e29d-cc03-4386-9095-9674bfd33c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  /home/ddpham/git/TFExam/data/aclImdb\n",
      "Subfolders of Path: ['imdbEr.txt', 'imdb.vocab', 'test', 'train', 'README']\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra path:\n",
    "print(\"Path: \", path)\n",
    "print(\"Subfolders of Path:\", os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7ea67-2097-4f89-9872-aa951fb9b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subfolders: ['labeledBow.feat', 'neg', 'urls_pos.txt', 'pos', 'urls_neg.txt'] \n",
      "Train subfolders: ['labeledBow.feat', 'neg', 'unsupBow.feat', 'urls_pos.txt', 'pos', 'urls_neg.txt', 'urls_unsup.txt', 'unsup']\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra subfolders:\n",
    "print(\"Test subfolders:\", os.listdir(os.path.join(path, 'test')), \n",
    "      \"\\nTrain subfolders:\", os.listdir(os.path.join(path, 'train')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c0a48-ee3a-4ae8-9229-3144d41c9fea",
   "metadata": {},
   "source": [
    "Chúng ta có thể thấy trong tập train có dữ liệu `unsup` là dữ liệu unsupervised của IMDB. Do đây là dữ liệu chúng ta sẽ không sử dụng nên cần được loại bỏ path trước khi load dữ liệu tạo tập train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda54b2f-d766-4e84-ac87-a058ab091b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample files in subfolders: \n",
      " ['713_1.txt', '10511_1.txt', '9228_3.txt', '9898_1.txt', '7524_1.txt', '7108_3.txt', '3376_3.txt', '485_3.txt', '8039_1.txt', '12103_3.txt']\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra subfolder:\n",
    "print(\"Sample files in subfolders: \\n\", os.listdir(os.path.join(path, 'train', 'neg'))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a5679-394a-403c-8ee3-df2ecef6efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I please say first of all, that I felt so strongly about this movie that I signed up to IMDb specifically to review it. And my review? This is easily the worst movie I have ever seen.<br /><br />The synopsis of the movie sounded interesting- Nazis, occult, time travel, etc., but the movies plot failed to properly bring all these elements together. Remember the episode of South Park that featured manatees writing Family Guy using 'idea balls'? Did these manatees also write Unholy? Its like the writer wanted to include all these different ideas, but had no idea how to link them all together, and then to make things make even less sense, included a Donnie Darko-esquire time travel theme to the ending, messing up the chronology.<br /><br />I could tell from early on that this was a bad movie. Special effects were too low budget for anything better than straight to DVD. The acting wasn't great, but in fairness I've seen worse. I will praise the Nazi paintings, they were creepy, but the evil Nazi butcher guy was just comic.<br /><br />I don't have a vendetta against this movie or anything, but to be honest, I'm not even into the horror genre. But this movie cannot be described as a thriller or a drama. If this story had been well told, this would have been a good movie. But it has been over hyped. Waaaaay over hyped.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu:\n",
    "with open(f'{path}/train/neg/713_1.txt') as file:\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a2d43-674e-473f-8bfe-59ae1516deaa",
   "metadata": {},
   "source": [
    "__Trước khi chúng ta bắt đầu, hãy loại bỏ subfolder unsup:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b931c7-e67e-4c91-8a77-adc84ae058c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Loại unsup khỏi path:\n",
    "remove_dir = os.path.join(path, 'train/unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058da338-cb2b-4f98-94bb-5de24b6a8839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'unsupBow.feat',\n",
       " 'urls_pos.txt',\n",
       " 'pos',\n",
       " 'urls_neg.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra lại directory:\n",
    "os.listdir(os.path.join(path, 'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24871c-f354-490e-93da-67d826861815",
   "metadata": {},
   "source": [
    "## Tạo dữ liệu\n",
    "> Với dữ liệu IMDB, chúng ta có thể dùng phương pháp `text_dataset_from_directory` tương tự như `image_dataset_from_directory` đã dùng với image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d840bc-cde1-4cf6-a113-e3a1bbca4324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_dataset_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inferred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Generates a `tf.data.Dataset` from text files in a directory.\n",
       "\n",
       "If your directory structure is:\n",
       "\n",
       "```\n",
       "main_directory/\n",
       "...class_a/\n",
       "......a_text_1.txt\n",
       "......a_text_2.txt\n",
       "...class_b/\n",
       "......b_text_1.txt\n",
       "......b_text_2.txt\n",
       "```\n",
       "\n",
       "Then calling `text_dataset_from_directory(main_directory, labels='inferred')`\n",
       "will return a `tf.data.Dataset` that yields batches of texts from\n",
       "the subdirectories `class_a` and `class_b`, together with labels\n",
       "0 and 1 (0 corresponding to `class_a` and 1 corresponding to `class_b`).\n",
       "\n",
       "Only `.txt` files are supported at this time.\n",
       "\n",
       "Arguments:\n",
       "  directory: Directory where the data is located.\n",
       "      If `labels` is \"inferred\", it should contain\n",
       "      subdirectories, each containing text files for a class.\n",
       "      Otherwise, the directory structure is ignored.\n",
       "  labels: Either \"inferred\"\n",
       "      (labels are generated from the directory structure),\n",
       "      or a list/tuple of integer labels of the same size as the number of\n",
       "      text files found in the directory. Labels should be sorted according\n",
       "      to the alphanumeric order of the text file paths\n",
       "      (obtained via `os.walk(directory)` in Python).\n",
       "  label_mode:\n",
       "      - 'int': means that the labels are encoded as integers\n",
       "          (e.g. for `sparse_categorical_crossentropy` loss).\n",
       "      - 'categorical' means that the labels are\n",
       "          encoded as a categorical vector\n",
       "          (e.g. for `categorical_crossentropy` loss).\n",
       "      - 'binary' means that the labels (there can be only 2)\n",
       "          are encoded as `float32` scalars with values 0 or 1\n",
       "          (e.g. for `binary_crossentropy`).\n",
       "      - None (no labels).\n",
       "  class_names: Only valid if \"labels\" is \"inferred\". This is the explict\n",
       "      list of class names (must match names of subdirectories). Used\n",
       "      to control the order of the classes\n",
       "      (otherwise alphanumerical order is used).\n",
       "  batch_size: Size of the batches of data. Default: 32.\n",
       "  max_length: Maximum size of a text string. Texts longer than this will\n",
       "    be truncated to `max_length`.\n",
       "  shuffle: Whether to shuffle the data. Default: True.\n",
       "      If set to False, sorts the data in alphanumeric order.\n",
       "  seed: Optional random seed for shuffling and transformations.\n",
       "  validation_split: Optional float between 0 and 1,\n",
       "      fraction of data to reserve for validation.\n",
       "  subset: One of \"training\" or \"validation\".\n",
       "      Only used if `validation_split` is set.\n",
       "  follow_links: Whether to visits subdirectories pointed to by symlinks.\n",
       "      Defaults to False.\n",
       "\n",
       "Returns:\n",
       "  A `tf.data.Dataset` object.\n",
       "    - If `label_mode` is None, it yields `string` tensors of shape\n",
       "      `(batch_size,)`, containing the contents of a batch of text files.\n",
       "    - Otherwise, it yields a tuple `(texts, labels)`, where `texts`\n",
       "      has shape `(batch_size,)` and `labels` follows the format described\n",
       "      below.\n",
       "\n",
       "Rules regarding labels format:\n",
       "  - if `label_mode` is `int`, the labels are an `int32` tensor of shape\n",
       "    `(batch_size,)`.\n",
       "  - if `label_mode` is `binary`, the labels are a `float32` tensor of\n",
       "    1s and 0s of shape `(batch_size, 1)`.\n",
       "  - if `label_mode` is `categorial`, the labels are a `float32` tensor\n",
       "    of shape `(batch_size, num_classes)`, representing a one-hot\n",
       "    encoding of the class index.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/text_dataset.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "?keras.preprocessing.text_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd8d0cc-9e9d-4062-ab76-2257f378e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Tạo tập train và valid từ folder train:\n",
    "train_ds = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory=f'{path}/train'\n",
    "    , labels='inferred'\n",
    "    , label_mode='binary'\n",
    "#     , class_names=['neg', 'pos']\n",
    "    , batch_size=32\n",
    "    , validation_split=0.2\n",
    "    , subset='training'\n",
    "    , seed=42\n",
    ")\n",
    "valid_ds = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory=f'{path}/train'\n",
    "    , labels = 'inferred'\n",
    "    , label_mode='binary'\n",
    "    , batch_size=32\n",
    "    , validation_split=0.2\n",
    "    , subset='validation'\n",
    "    , seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad786df-8592-4d2f-b016-7bc8710dcb04",
   "metadata": {},
   "source": [
    "__Lưu ý:__\n",
    "Chúng ta luôn luôn nhớ cần kiểm tra lại dữ liệu sau tất cả các bước load dữ liệu, biến đổi dữ liệu và tạo features để đảm bảo dữ liệu đầu ra đúng với yêu cầu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f247694-a963-4866-aee2-ef354ab262a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      " b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
      " b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'], shape=(3,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra lại dữ liệu từ tập train:\n",
    "for batch in train_ds.take(1):\n",
    "    print(batch[0][:3])\n",
    "    print(batch[1][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a2e21-88aa-48a8-9ba6-1ba45a89fb4e",
   "metadata": {},
   "source": [
    "## Text Vectorization\n",
    "> Chúng ta sử dụng TextVectorization để tokenize text và convert text về dạng sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6da1cb-6376-4cc7-9067-db00619721fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Text vectorization layer.\n",
       "\n",
       "This layer has basic options for managing text in a Keras model. It\n",
       "transforms a batch of strings (one sample = one string) into either a list of\n",
       "token indices (one sample = 1D tensor of integer token indices) or a dense\n",
       "representation (one sample = 1D tensor of float values representing data about\n",
       "the sample's tokens).\n",
       "\n",
       "If desired, the user can call this layer's adapt() method on a dataset.\n",
       "When this layer is adapted, it will analyze the dataset, determine the\n",
       "frequency of individual string values, and create a 'vocabulary' from them.\n",
       "This vocabulary can have unlimited size or be capped, depending on the\n",
       "configuration options for this layer; if there are more unique values in the\n",
       "input than the maximum vocabulary size, the most frequent terms will be used\n",
       "to create the vocabulary.\n",
       "\n",
       "The processing of each sample contains the following steps:\n",
       "\n",
       "  1. standardize each sample (usually lowercasing + punctuation stripping)\n",
       "  2. split each sample into substrings (usually words)\n",
       "  3. recombine substrings into tokens (usually ngrams)\n",
       "  4. index tokens (associate a unique int value with each token)\n",
       "  5. transform each sample using this index, either into a vector of ints or\n",
       "     a dense float vector.\n",
       "\n",
       "Some notes on passing Callables to customize splitting and normalization for\n",
       "this layer:\n",
       "\n",
       "  1. Any callable can be passed to this Layer, but if you want to serialize\n",
       "     this object you should only pass functions that are registered Keras\n",
       "     serializables (see `tf.keras.utils.register_keras_serializable` for more\n",
       "     details).\n",
       "  2. When using a custom callable for `standardize`, the data received\n",
       "     by the callable will be exactly as passed to this layer. The callable\n",
       "     should return a tensor of the same shape as the input.\n",
       "  3. When using a custom callable for `split`, the data received by the\n",
       "     callable will have the 1st dimension squeezed out - instead of\n",
       "     `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n",
       "     see `[\"string to split\", \"another string to split\"]`. The callable should\n",
       "     return a Tensor with the first dimension containing the split tokens -\n",
       "     in this example, we should see something like `[[\"string\", \"to\", \"split],\n",
       "     [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable site\n",
       "     natively compatible with `tf.strings.split()`.\n",
       "\n",
       "Attributes:\n",
       "  max_tokens: The maximum size of the vocabulary for this layer. If None,\n",
       "    there is no cap on the size of the vocabulary. Note that this vocabulary\n",
       "    contains 1 OOV token, so the effective number of tokens is `(max_tokens -\n",
       "    1 - (1 if output == \"int\" else 0))`.\n",
       "  standardize: Optional specification for standardization to apply to the\n",
       "    input text. Values can be None (no standardization),\n",
       "    'lower_and_strip_punctuation' (lowercase and remove punctuation) or a\n",
       "    Callable. Default is 'lower_and_strip_punctuation'.\n",
       "  split: Optional specification for splitting the input text. Values can be\n",
       "    None (no splitting), 'whitespace' (split on ASCII whitespace), or a\n",
       "    Callable. The default is 'whitespace'.\n",
       "  ngrams: Optional specification for ngrams to create from the possibly-split\n",
       "    input text. Values can be None, an integer or tuple of integers; passing\n",
       "    an integer will create ngrams up to that integer, and passing a tuple of\n",
       "    integers will create ngrams for the specified values in the tuple. Passing\n",
       "    None means that no ngrams will be created.\n",
       "  output_mode: Optional specification for the output of the layer. Values can\n",
       "    be \"int\", \"binary\", \"count\" or \"tf-idf\", configuring the layer as follows:\n",
       "      \"int\": Outputs integer indices, one integer index per split string\n",
       "        token. When output == \"int\", 0 is reserved for masked locations;\n",
       "        this reduces the vocab size to max_tokens-2 instead of max_tokens-1\n",
       "      \"binary\": Outputs a single int array per batch, of either vocab_size or\n",
       "        max_tokens size, containing 1s in all elements where the token mapped\n",
       "        to that index exists at least once in the batch item.\n",
       "      \"count\": As \"binary\", but the int array contains a count of the number\n",
       "        of times the token at that index appeared in the batch item.\n",
       "      \"tf-idf\": As \"binary\", but the TF-IDF algorithm is applied to find the\n",
       "        value in each token slot.\n",
       "  output_sequence_length: Only valid in INT mode. If set, the output will have\n",
       "    its time dimension padded or truncated to exactly `output_sequence_length`\n",
       "    values, resulting in a tensor of shape [batch_size,\n",
       "    output_sequence_length] regardless of how many tokens resulted from the\n",
       "    splitting step. Defaults to None.\n",
       "  pad_to_max_tokens: Only valid in  \"binary\", \"count\", and \"tf-idf\" modes. If\n",
       "    True, the output will have its feature axis padded to `max_tokens` even if\n",
       "    the number of unique tokens in the vocabulary is less than max_tokens,\n",
       "    resulting in a tensor of shape [batch_size, max_tokens] regardless of\n",
       "    vocabulary size. Defaults to True.\n",
       "  vocabulary: An optional list of vocabulary terms, or a path to a text file\n",
       "    containing a vocabulary to load into this layer. The file should contain\n",
       "    one token per line. If the list or file contains the same token multiple\n",
       "    times, an error will be thrown.\n",
       "\n",
       "Example:\n",
       "This example instantiates a TextVectorization layer that lowercases text,\n",
       "splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
       "\n",
       ">>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
       ">>> max_features = 5000  # Maximum vocab size.\n",
       ">>> max_len = 4  # Sequence length to pad the outputs to.\n",
       ">>> embedding_dims = 2\n",
       ">>>\n",
       ">>> # Create the layer.\n",
       ">>> vectorize_layer = TextVectorization(\n",
       "...  max_tokens=max_features,\n",
       "...  output_mode='int',\n",
       "...  output_sequence_length=max_len)\n",
       ">>>\n",
       ">>> # Now that the vocab layer has been created, call `adapt` on the text-only\n",
       ">>> # dataset to create the vocabulary. You don't have to batch, but for large\n",
       ">>> # datasets this means we're not keeping spare copies of the dataset.\n",
       ">>> vectorize_layer.adapt(text_dataset.batch(64))\n",
       ">>>\n",
       ">>> # Create the model that uses the vectorize text layer\n",
       ">>> model = tf.keras.models.Sequential()\n",
       ">>>\n",
       ">>> # Start by creating an explicit input layer. It needs to have a shape of\n",
       ">>> # (1,) (because we need to guarantee that there is exactly one string\n",
       ">>> # input per batch), and the dtype needs to be 'string'.\n",
       ">>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
       ">>>\n",
       ">>> # The first layer in our model is the vectorization layer. After this\n",
       ">>> # layer, we have a tensor of shape (batch_size, max_len) containing vocab\n",
       ">>> # indices.\n",
       ">>> model.add(vectorize_layer)\n",
       ">>>\n",
       ">>> # Now, the model can map strings to integers, and you can add an embedding\n",
       ">>> # layer to map these integers to learned embeddings.\n",
       ">>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
       ">>> model.predict(input_data)\n",
       "array([[2, 1, 4, 0],\n",
       "       [1, 3, 0, 0]])\n",
       "\n",
       "Example:\n",
       "This example instantiates a TextVectorization layer by passing a list\n",
       "of vocabulary terms to the layer's __init__ method.\n",
       "\n",
       "  input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n",
       "                          [\"fire\", \"and\", \"earth\", \"michigan\"]])\n",
       "  expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n",
       "\n",
       "  input_data = keras.Input(shape=(None,), dtype=dtypes.string)\n",
       "  layer = get_layer_class()(\n",
       "      max_tokens=None,\n",
       "      standardize=None,\n",
       "      split=None,\n",
       "      output_mode=text_vectorization.INT,\n",
       "      vocabulary=vocab_data)\n",
       "  int_data = layer(input_data)\n",
       "  model = keras.Model(inputs=input_data, outputs=int_data)\n",
       "\n",
       "  output_dataset = model.predict(input_array)\n",
       ">>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n",
       ">>> max_len = 4  # Sequence length to pad the outputs to.\n",
       ">>>\n",
       ">>> # Create the layer, passing the vocab directly. You can also pass the\n",
       ">>> # vocabulary arg a path to a file containing one vocabulary word per\n",
       ">>> # line.\n",
       ">>> vectorize_layer = TextVectorization(\n",
       "...  max_tokens=max_features,\n",
       "...  output_mode='int',\n",
       "...  output_sequence_length=max_len,\n",
       "...  vocabulary=vocab_data)\n",
       ">>>\n",
       ">>> # Because we've passed the vocabulary directly, we don't need to adapt\n",
       ">>> # the layer - the vocabulary is already set. The vocabulary contains the\n",
       ">>> # padding token ('') and OOV token ('[UNK]') as well as the passed tokens.\n",
       ">>> vectorize_layer.get_vocabulary()\n",
       "['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     TextVectorization\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "?keras.layers.experimental.preprocessing.TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6b589-04a7-4851-8e8a-a43caae0ac88",
   "metadata": {},
   "source": [
    "### Biến đổi dữ liệu cơ bản\n",
    "> Trong layer text vectorization, có biến: `standardize` giúp chúng ta thực hiện các bước biến đổi/chuẩn hóa dữ liệu như: chuyển chữ về dạng lowercase (tùy chọn, có thể ko sử dụng nếu bạn thấy không cần thiết); loại bỏ các ký tự đặc biệt sử dụng trong ngôn ngữ html... Đây là các bước cần thiết để chúng ta có được dữ liệu sạch và chuẩn trước khi chúng ta bắt đầu việc tách từ, gộp từ, tokenize từ và tạo sequence (vector) hoặc tf-idf..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0992cfb-93be-4f2a-a123-ce30645a3e81",
   "metadata": {},
   "source": [
    "__Lưu ý:__\n",
    "\n",
    "Tensorflow có module `strings` có rất nhiều phương pháp xử lý dữ liệu dạng chữ khác nhau rất hữu dụng để chúng ta có thể sử dụng biến đổi dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa61b81-d02e-401e-b6d3-ef0c9a7ffec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'as_string',\n",
       " 'bytes_split',\n",
       " 'format',\n",
       " 'join',\n",
       " 'length',\n",
       " 'lower',\n",
       " 'ngrams',\n",
       " 'reduce_join',\n",
       " 'regex_full_match',\n",
       " 'regex_replace',\n",
       " 'split',\n",
       " 'strip',\n",
       " 'substr',\n",
       " 'to_hash_bucket',\n",
       " 'to_hash_bucket_fast',\n",
       " 'to_hash_bucket_strong',\n",
       " 'to_number',\n",
       " 'unicode_decode',\n",
       " 'unicode_decode_with_offsets',\n",
       " 'unicode_encode',\n",
       " 'unicode_script',\n",
       " 'unicode_split',\n",
       " 'unicode_split_with_offsets',\n",
       " 'unicode_transcode',\n",
       " 'unsorted_segment_join',\n",
       " 'upper']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "dir(tf.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488db94-f310-4d8d-9c11-b0dc86508184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def text_cleansing(input_text):\n",
    "    # Convert sang lower case:\n",
    "    lower_text = tf.strings.lower(input_text)\n",
    "    # Loại bỏ các ký tự html:\n",
    "    html_text = tf.strings.regex_replace(lower_text, \"<br />\", \" \")\n",
    "    # Loại bỏ các dấu:\n",
    "    puct_text = tf.strings.regex_replace(html_text, \"[%s]\" % re.escape(string.punctuation), \"\")\n",
    "    return puct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de0b78-aeb6-4a55-aca2-2b9ce8b7879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Danh sách puntuations:\n",
    "'[%s]' % re.escape(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a09669-3782-41fe-bf80-78f71c587f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04a36a-da9a-455e-b390-97e0f3abf13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\", shape=(), dtype=string) \n",
      "\n",
      "tf.Tensor(b'david mamet is a very interesting and a very unequal director his first movie house of games was the one i liked best and it set a series of films with characters whose perspective of life changes as they get into complicated situations and so does the perspective of the viewer  so is homicide which from the title tries to set the mind of the viewer to the usual crime drama the principal characters are two cops one jewish and one irish who deal with a racially charged area the murder of an old jewish shop owner who proves to be an ancient veteran of the israeli independence war triggers the jewish identity in the mind and heart of the jewish detective  this is were the flaws of the film are the more obvious the process of awakening is theatrical and hard to believe the group of jewish militants is operatic and the way the detective eventually walks to the final violent confrontation is pathetic the end of the film itself is mametlike smart but disappoints from a human emotional perspective  joe mantegna and william macy give strong performances but the flaws of the story are too evident to be easily compensated', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Test thử dữ liệu:\n",
    "for batch in train_ds.take(1):\n",
    "    print(batch[0][1], '\\n')\n",
    "    print(text_cleansing(batch[0][1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c707207-3e25-43fb-b68a-dbecc394e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Tạo layer vectorization:\n",
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorization_layer = keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=max_features\n",
    "    , standardize=text_cleansing\n",
    "    , split='whitespace'\n",
    "    , ngrams=None\n",
    "    , output_mode='int'\n",
    "    , output_sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d148d-ba1d-4455-8f39-5426888deb3c",
   "metadata": {},
   "source": [
    "**Lưu ý:**\n",
    "\n",
    "Tưowng tự như `Tokenizer` trong `keras.preprocesisng.text`, TextVectorization có phương pháp `adapt` để giúp chúng ta xây dựng vocabulary cho tập dữ liệu dựa vào tập train. Do đó trước khi bắt đầu tiếp các bước tiếp theo, chúng ta sẽ `adapt` TextVectorization với tập dữ liệu train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee054d-60b1-4385-ad49-a6892bc2da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Gộp toàn bộ dữ liệu text vào:\n",
    "for _, text in train_ds.enumerate():\n",
    "    if _ == 0:\n",
    "        raw_text_train = text[0]\n",
    "    else: raw_text_train = tf.concat([raw_text_train, text[0]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6448db-d493-4e7c-86aa-7b4787f88238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#:  20000\n",
      "Sample data:\n",
      " tf.Tensor(\n",
      "[b'Silent Night, Deadly Night 5 is the very last of the series, and like part 4, it\\'s unrelated to the first three except by title and the fact that it\\'s a Christmas-themed horror flick.<br /><br />Except to the oblivious, there\\'s some obvious things going on here...Mickey Rooney plays a toymaker named Joe Petto and his creepy son\\'s name is Pino. Ring a bell, anyone? Now, a little boy named Derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him. Even though it said \"don\\'t open till Christmas\", he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself. Inside is a little red ball that sprouts Santa arms and a head, and proceeds to kill dad. Oops, maybe he should have left well-enough alone. Of course Derek is then traumatized by the incident since he watched it from the stairs, but he doesn\\'t grow up to be some killer Santa, he just stops talking.<br /><br />There\\'s a mysterious stranger lurking around, who seems very interested in the toys that Joe Petto makes. We even see him buying a bunch when Derek\\'s mom takes him to the store to find a gift for him to bring him out of his trauma. And what exactly is this guy doing? Well, we\\'re not sure but he does seem to be taking these toys apart to see what makes them tick. He does keep his landlord from evicting him by promising him to pay him in cash the next day and presents him with a \"Larry the Larvae\" toy for his kid, but of course \"Larry\" is not a good toy and gets out of the box in the car and of course, well, things aren\\'t pretty.<br /><br />Anyway, eventually what\\'s going on with Joe Petto and Pino is of course revealed, and as with the old story, Pino is not a \"real boy\". Pino is probably even more agitated and naughty because he suffers from \"Kenitalia\" (a smooth plastic crotch) so that could account for his evil ways. And the identity of the lurking stranger is revealed too, and there\\'s even kind of a happy ending of sorts. Whee.<br /><br />A step up from part 4, but not much of one. Again, Brian Yuzna is involved, and Screaming Mad George, so some decent special effects, but not enough to make this great. A few leftovers from part 4 are hanging around too, like Clint Howard and Neith Hunter, but that doesn\\'t really make any difference. Anyway, I now have seeing the whole series out of my system. Now if I could get some of it out of my brain. 4 out of 5.'\n",
      " b\"This Italian film from the '70's is NOT even in the class with Dog Soldiers, The Howling, or even that awful American Werewolf in Paris, BUT...it is fun to watch. I'm talking about watching the lead actress, a stunning blonde, run amok in her birthday suit. We're talking about graphic, complete nudity...it's obvious that she is a real blonde...humma humma humma!! The story is a hoot, the SFX are childish, and the acting (for the most part) stinks. The only redeeming value of this movie is all (and there is a LOT) the nudity & sex scenes. Tame by HBO standards, but still fun to see when you find yourself without a date on Saturday night. OK...HERE'S THE SPOILER...There is NO werewolf (except in the opening scene of the heroine(??)'s ancestor. The girl just imagines that she's a werewolf...in other words, a clinical Lycanthrope.\"\n",
      " b'Mr Perlman gives a standout performance (as usual). Sadly, he has to struggle with an underwritten script and some nonsensical set pieces.<br /><br />Larsen is in \"Die Hard\" mode complete with singlet and bulging muscles, I\\'m sure he could do better but seems satisfied to grimace and snarl through his part.<br /><br />The lovely Erika is very decorative (even though fully clothed!) and shows some signs of \"getting\" acting at last.<br /><br />SFX are mainly poor CGI and steals from other movies.<br /><br />The shootouts are pitiful - worthy of the A-Team<br /><br />Not even worth seeing for Perlman - AVOID'\n",
      " b\"I'm a Christian who generally believes in the theology taught in Left Behind. That being said, I think Left Behind is one of the worst films I've seen in some time.<br /><br />To have a good movie, you need to have a well-written screenplay. Left Behind fell woefully short on this. For one thing, it radically deviates from the book. Sometimes this is done to condense a 400-page novel down to a two-hour film, but in this film I saw changes that made no sense whatsoever.<br /><br />Another thing, there is zero character development. When characters in the story get saved (I won't say who), the book makes it clear that it's a long, soul-searching process. In the film it's quick and artificial. The book is written decently enough where people like Rayford Steele, Buck Williams and Hattie Durham seem real, but in the movie scenarios are consistently given the quick treatment without anything substantial. In another scene where one character gets angry about being left behind (again, I won't say who), it seems artificial.<br /><br />I realize as a Christian it's unedifying for me to say I disliked this film, but I can't in a good conscience recommend a film that I feel was horribly done. Perhaps it would've been better to make the first book into 2-3 films. Either way, Christians need to realize that to be taken seriously as filmmakers, we need to start by putting together a film in a quality way. I realize a lot of effort probably went into Left Behind, but that's the way I see it.\"\n",
      " b'The Forest isn\\'t just your everyday standard slasher/backwoods cannibal fare, it also has an interesting mix of supernatural elements as well. The story is about two couples that hike into the forest on a camping trip. A cave dwelling, cannibalistic woodsmen and the ghosts of his dead wife and two children soon terrorize them. There is something you don\\'t see every slasher. Director Don Jones gets an \"A\" for effort although the film itself falls flat on just about every level, the acting is just simply average except for Jeanette Kelly who plays the dead wife of the woodsman (Michael Brody aka Gary Kent).<br /><br />The film opens with some beautiful shots of a couple hiking through a valley and into a forest. They realize too late that someone is stalking them. They are both dispatched in typical slasher fare. Our killer uses a trusty hunting knife throughout the entire film, except during a flashback when he implements a handsaw, pitchfork and rusty saw blade to dispatch his cheating wife\\'s lover.<br /><br />The Forest has a good story line but the movie just doesn\\'t work along with it I found it pretty boring with simply crappy acting. 4/10'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu:\n",
    "print(\"#: \", raw_text_train.shape[0])\n",
    "print(\"Sample data:\\n\", raw_text_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac647a-d25c-491b-b5b6-5bbc0a930b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Adapt vectorization_layer với dữ liệu text từ tập train:\n",
    "vectorization_layer.adapt(raw_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffbc5b-a874-419e-bc87-9c5783c93e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
       "array([[1287,  313, 2380,  313,  661,    7,    2,   52,  229,    5,    2,\n",
       "         200,    3,   38,  170,  669,   29, 5492,    6,    2,   83,  297,\n",
       "         549,   32,  410,    3,    2,  186,   12,   29,    4,    1,  191,\n",
       "         510,  549,    6,    2, 8229,  212,   46,  576,  175,  168,   20,\n",
       "           1, 5361,  290,    4,    1,  761,  969,    1,    3,   24,  935,\n",
       "        2271,  393,    7,    1, 1675,    4, 3747,  250,  148,    4,  112,\n",
       "         436,  761, 3529,  548,    4, 3633,   31,    2, 1331,   28, 2096,\n",
       "           3, 2912,    9,    6,  163,    4, 1006,   20,    2,    1,   15,\n",
       "          85,   53,  147,    9,  292,   89,  959, 2314,  984,   27,  762,\n",
       "           6,  959,    9,  564,   18,    7, 2140,   32,   24, 1254,   36,\n",
       "           1,   85,    3, 3298,   85,    6, 1410,    3, 1936,    2, 3408,\n",
       "         301,  965,    7,    4,  112,  740, 1977,   12,    1, 2014, 2772,\n",
       "           3,    4,  428,    3, 5177,    6,  512, 1254,    1,  278,   27,\n",
       "         139,   25,  308,    1,  579,    5,  259, 3529,    7,   92, 8981,\n",
       "          32,    2, 3842,  230,   27,  289,    9,   35,    2, 5712,   18,\n",
       "          27,  144, 2166,   56,    6,   26,   46,  466, 2014,   27,   40,\n",
       "        2745,  657,  212,    4, 1376, 3002, 7080,  183,   36,  180,   52,\n",
       "         920,    8,    2, 4028,   12,  969,    1,  158,   71,   53,   67,\n",
       "          85, 2754,    4,  734,   51,    1, 1611,  294,   85,    6,    2,\n",
       "        1164,    6,  163,    4, 3408,   15,   85,    6,  717,   85,   44,\n",
       "           5,   24, 7158,    3,   48,  604,    7,   11,  225,  384,   73,\n",
       "          65,   21,  242,   18,   27,  120,  295,    6,   26,  667,  129,\n",
       "        4028,  948,    6,   67,   48,  158,   93,    1]])>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra lại với 1 sample:\n",
    "## Lưu ý: dữ liệu đầu vào của vectorization_layer phải là dạng list, nên ở đây\n",
    "## với 1 sample của raw_text_train, chúng ta phải biến nó thành dạng list:\n",
    "vectorization_layer([raw_text_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b581ce-6f2b-42e0-8247-f7d1c63950de",
   "metadata": {},
   "source": [
    "**Lưu ý:**\n",
    "Bằng cách sử dụng toàn bộ dữ liệu text của tập train để xây dựng vocab cho layer vectorization, chúng ta đã có được phần này đầy đủ. Hãy áp dụng cho các tập dữ liệu khác:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5aebd-eebb-4af4-91bf-901cae07b5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None, 1)), types: (tf.string, tf.float32)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra shape của dữ liệu đầu vào:\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df0ea6-ddd6-4e0f-a28c-f2b04f81a6fa",
   "metadata": {},
   "source": [
    "Đôi khi, chúng ta có thể quên mất loại dữ liệu của tập train/valid (dạng tuple hoặc dictionary). Trước khi áp dụng phương pháp nào vào dữ liệu này, bạn cần biết rõ dạng dữ liệu để đảm bảo khi tạo phương pháp, chúng ta ko bị nhầm lẫn giữa 2 loại dữ liệu trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5395f-0bee-4f3f-a5a5-6926795ec0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Tạo hàm biến đổi dữ liệu để map vào các tập dataset;\n",
    "def vectorize_text(text, label):\n",
    "    \n",
    "    # Biến đổi từng comment thành dạng list:\n",
    "    text = tf.expand_dims(text, -1) \n",
    "    return vectorization_layer(text), label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa007020-632f-4682-a9ee-edf05b4e6052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original comment:\n",
      " tf.Tensor(b\"I am shocked. Shocked and dismayed that the 428 of you IMDB users who voted before me have not given this film a rating of higher than 7. 7?!?? - that's a C!. If I could give FOBH a 20, I'd gladly do it. This film ranks high atop the pantheon of modern comedy, alongside Half Baked and Mallrats, as one of the most hilarious films of all time. If you know _anything_ about rap music - YOU MUST SEE THIS!! If you know nothing about rap music - learn something!, and then see this! Comparisons to 'Spinal Tap' fail to appreciate the inspired genius of this unique film. If you liked Bob Roberts, you'll love this. Watch it and vote it a 10!\", shape=(), dtype=string) \n",
      "\n",
      "Vectorized comment:'\n",
      " (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
      "array([[  10,  237, 2350, 2350,    3,    1,   12,    2,    1,    5,   22,\n",
      "         922, 5790,   36, 5633,  153,   69,   25,   21,  340,   11,   19,\n",
      "           4,  693,    5, 1718,   70, 1131, 1131,  177,    4, 1885,   45,\n",
      "          10,   98,  193,    1,    4,  950,  450,    1,   82,    9,   11,\n",
      "          19, 3798,  331,    1,    2,    1,    5,  709,  220, 4475,  363,\n",
      "           1,    3,    1,   14,   28,    5,    2,   88,  615,   94,    5,\n",
      "          30,   58,   45,   22,  118,  228,   42, 3662,  222,   22,  219,\n",
      "          67,   11,   45,   22,  118,  155,   42, 3662,  222,  817,  138,\n",
      "           3,   92,   67,   11, 5471,    6, 5572, 4139, 1760,    6, 1111,\n",
      "           2, 1534, 1209,    5,   11,  953,   19,   45,   22,  414, 1956,\n",
      "        2985,  483,  115,   11,  103,    9,    3, 2187,    9,    4,  296,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Thử test với 1 batch của tập train:\n",
    "for batch in train_ds.take(1):\n",
    "    print(\"Original comment:\\n\", batch[0][1], '\\n')\n",
    "    print(\"Vectorized comment:'\\n\", vectorize_text(batch[0][1], batch[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5b241-3fc2-4f5d-9ab9-ae2ed420adc4",
   "metadata": {},
   "source": [
    "**Lưu ý:**\n",
    "\n",
    "Chúng ta có thể thấy, với độ dài của sequence = 250, không phải comment nào cũng đủ dài như vậy, nên sẽ có những comment khi biến đổi sang sequence thì có rất nhiều giá trị 0 đằng sau được `pad` vào để đảm bảo độ dài của sequence = 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37115c-3e93-4cdd-81bf-f1068f881d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Áp dụng với tập train và valid:\n",
    "train_ds = train_ds.map(vectorize_text)\n",
    "valid_ds = valid_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265745a4-e2ca-40a7-95aa-912e4e3d0445",
   "metadata": {},
   "source": [
    "### Cấu hình dữ liệu\n",
    "> Với dữ liệu dạng Dataset, chúng ta có 2 phương pháp cấu hình dữ liệu có thể áp dụng để tránh bị vấn để về I/O: `cache` và `prefetch`.\n",
    "Về cơ bản `cache` là việc máy sẽ ưu tiên một phần của bộ nhớ tạm thời (RAM) (hoặc ổ cứng tại máy local - vs hệ thống dữ liệu ditributed) cho dữ liệu còn `prefetch` là việc máy (CPU) sẽ tính toán trước dữ liệu cho batch tiếp theo khi model đang train batch hiện tại trên GPU. Bạn có thể thấy là với Tensorflow, chúng ta phải tương đối am hiểu về những kiến thức cơ bản của CS để có thể hiểu được ý nghĩa của việc tuning performance như thế này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d3f32-185c-4f56-84ff-8e6806cf51e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        int\n",
       "\u001b[0;31mString form:\u001b[0m -1\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "int([x]) -> integer\n",
       "int(x, base=10) -> integer\n",
       "\n",
       "Convert a number or string to an integer, or return 0 if no arguments\n",
       "are given.  If x is a number, return x.__int__().  For floating point\n",
       "numbers, this truncates towards zero.\n",
       "\n",
       "If x is not a number or if base is given, then x must be a string,\n",
       "bytes, or bytearray instance representing an integer literal in the\n",
       "given base.  The literal can be preceded by '+' or '-' and be surrounded\n",
       "by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.\n",
       "Base 0 means to interpret the base from the string as an integer literal.\n",
       ">>> int('0b100', base=0)\n",
       "4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "?tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847b348-8d60-48a6-85fd-b24c648b1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "AUTOTUNE = tf.data.AUTOTUNE # để tf tự quyết định số lượng prefetch dựa vào cấu hình của máy tính \n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8afd53-1d71-4434-ac75-dfc79c90b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 250), (None, 1)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra lại shape của dữ liệu:\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0670323-f5c9-48aa-90d3-feaf48f468c6",
   "metadata": {},
   "source": [
    "## Tạo model cơ bản\n",
    "> Chúng ta sẽ tạo 1 model có cấu trúc tương đối đơn giản: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287cc89b-8376-4378-b396-9532ec7ca2d9",
   "metadata": {},
   "source": [
    "### Xây dựng kiến trúc cơ bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4207a-7984-46ae-ae20-23256ffff6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 64)           640000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 640,661\n",
      "Trainable params: 640,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Tạo kiến trúc cơ bản:\n",
    "embedding_dim = 64\n",
    "model = keras.Sequential()\n",
    "    \n",
    "# Tạo embedding layer:\n",
    "model.add(keras.layers.Embedding(max_features, embedding_dim, input_length=sequence_length))\n",
    "\n",
    "# Dropout\n",
    "model.add(keras.layers.Dropout(.2))\n",
    "\n",
    "# Sử dụng globalaveragepool1D để giảm chiều và lấy\n",
    "# giá trị average của từng row của matrix embeding\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "\n",
    "# Tiếp tục dropout:\n",
    "model.add(keras.layers.Dropout(.2))\n",
    "\n",
    "# Tạo dense layer để tiếp tục giảm size:\n",
    "model.add(keras.layers.Dense(10, activation='relu'))\n",
    "\n",
    "# Tạo layer dự báo:\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model:\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e17736-7260-4111-aef6-d260d0b8f5ca",
   "metadata": {},
   "source": [
    "### Đào tạo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41f2b2-0d8c-4034-a4fb-bdc7fbdb9790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 20s 29ms/step - loss: 0.6461 - accuracy: 0.6603 - val_loss: 0.4115 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3639 - accuracy: 0.8555 - val_loss: 0.3165 - val_accuracy: 0.8656\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.2820 - accuracy: 0.8864 - val_loss: 0.2983 - val_accuracy: 0.8762\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.2479 - accuracy: 0.9012 - val_loss: 0.2940 - val_accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.2271 - accuracy: 0.9114 - val_loss: 0.2918 - val_accuracy: 0.8790\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.2133 - accuracy: 0.9195 - val_loss: 0.2952 - val_accuracy: 0.8780\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 18s 29ms/step - loss: 0.2026 - accuracy: 0.9227 - val_loss: 0.2954 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.1938 - accuracy: 0.9265 - val_loss: 0.2959 - val_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 18s 30ms/step - loss: 0.1877 - accuracy: 0.9308 - val_loss: 0.2982 - val_accuracy: 0.8808\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.1818 - accuracy: 0.9326 - val_loss: 0.3010 - val_accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f88fe6c12b0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "# Train model:\n",
    "epochs = 10\n",
    "model.fit(train_ds, epochs=epochs, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736673f0-237f-475e-ad66-01f88a0e9e61",
   "metadata": {},
   "source": [
    "Chúng ta có thể thấy, kể từ epoch thứ 3 trở đi, model bắt đầu có dấu hiệu overfit. Chúng ta có thể plot lại kết quả để dễ  hình dung hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de4638-4f5a-4cfa-8779-a80b2194b3cf",
   "metadata": {},
   "source": [
    "### Visualize kết quả\n",
    "> Keras có lưu lại kết quả trong quá trình train model ở model.history, bao gồm cả dữ liệu về loss và metrics. Chúng ta hãy plot lại dữ liệu này theo epoch để dễ quan sát hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07befd-e72d-4f41-8f61-2a30ca80c14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5900413990020752,\n",
       "  0.35086187720298767,\n",
       "  0.2806062698364258,\n",
       "  0.25015172362327576,\n",
       "  0.2301107943058014,\n",
       "  0.2160499095916748,\n",
       "  0.20527395606040955,\n",
       "  0.1980276256799698,\n",
       "  0.19125179946422577,\n",
       "  0.18440547585487366],\n",
       " 'accuracy': [0.7352499961853027,\n",
       "  0.8586500287055969,\n",
       "  0.8848000168800354,\n",
       "  0.902400016784668,\n",
       "  0.9103000164031982,\n",
       "  0.9168499708175659,\n",
       "  0.9230999946594238,\n",
       "  0.9257000088691711,\n",
       "  0.9285500049591064,\n",
       "  0.9313499927520752],\n",
       " 'val_loss': [0.4314160645008087,\n",
       "  0.31800544261932373,\n",
       "  0.2969827353954315,\n",
       "  0.2911377251148224,\n",
       "  0.28976067900657654,\n",
       "  0.2912695109844208,\n",
       "  0.2928432822227478,\n",
       "  0.29422780871391296,\n",
       "  0.2965157628059387,\n",
       "  0.29804882407188416],\n",
       " 'val_accuracy': [0.8339999914169312,\n",
       "  0.8669999837875366,\n",
       "  0.876800000667572,\n",
       "  0.879800021648407,\n",
       "  0.8820000290870667,\n",
       "  0.8813999891281128,\n",
       "  0.8822000026702881,\n",
       "  0.8831999897956848,\n",
       "  0.8835999965667725,\n",
       "  0.8826000094413757]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu hisotry:\n",
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad812200-d766-4148-8af6-4f4d15e4c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_history(history: dict, metrics:str='accuracy'):\n",
    "    # Tạo list cần plot:\n",
    "    loss = [i for i in history if 'loss' in i]\n",
    "    metrics = [i for i in history if f'{metrics}' in i]\n",
    "    plots = [loss, metrics]\n",
    "    \n",
    "    # Plot:\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    for i in range(len(plots)):\n",
    "        ax = plt.subplot(1, 2, i+1)\n",
    "        for plot_item in plots[i]:\n",
    "            ax.plot(history[plot_item])\n",
    "            ax.legend(plots[i])\n",
    "            ax.set_xlabel('epochs')\n",
    "    plt.suptitle(\"Train's and Validation's Loss vs Metrics\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598c20e-3cb9-4aa2-8e94-eda00d84d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "plot_history(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ae4d2-3837-4bd8-a27e-c045b298d558",
   "metadata": {},
   "source": [
    "Chúng ta tạm thời chấp nhận kết quả này ở đây và chuyển sang "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6379b2-627f-4d07-a389-74040ce40a9f",
   "metadata": {},
   "source": [
    "### Đánh giá kết quả\n",
    "> Sau khi đã hài lòng với kết quả được đào tạo. Chúng ta có thể đánh giá lại tính chính xác của model vs tập test. Ở bước trên, chúng ta đã không hề đề cập đến tập dữ liệu test, bây giờ là lúc để load dữ liệu và kiểm định lại model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a6199-0918-468b-a6a9-09c3504ebb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "test_ds = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory=f'{path}/test'\n",
    "    , labels = 'inferred'\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bbc05-8734-4894-ba6d-3ac3df00aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New comment:\n",
      " [  84    5    2 1101    5   24  106 5976    3 4508    5   63  402  571\n",
      "    1  482   82   21  664 6576   81   19  240  307 7517    8   24  229\n",
      "   19  153   24  323 3120    4  397 3872    5    1   63   27 1944   86\n",
      " 1450   35   24  489   14  787    3  567   14  516    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "\n",
      "Label:\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra lại dữ liệu:\n",
    "for text in test_ds.take(1):\n",
    "    print(\"New comment:\\n\", text[0][1].numpy())\n",
    "    print(\"\\nLabel:\\n\", text[1][1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573f580-8b26-45ec-8559-a9d6cf40d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá kết quả trên tập test:\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.3268 - accuracy: 0.8685\n",
      "Giá trị loss: 0.3268018662929535\n",
      "Giá trị accuary: 0.8685200214385986\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "print(\"Đánh giá kết quả trên tập test:\")\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Giá trị loss:\", loss)\n",
    "print(\"Giá trị accuary:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad38437-c61b-4642-b23b-6ece6255e37f",
   "metadata": {},
   "source": [
    "**Lưu ý:**\n",
    "Chúng ta có thể thấy giá trị của metric accuracy ở đây đang thấp hơn 1 chút so với tập valid và train ở bước trên, nhưng tương đối gần với tập valid (1% thấp hơn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2225f7f-d5d5-4c75-80ad-5c0075b14964",
   "metadata": {},
   "source": [
    "### Dự đoán\n",
    "> Sau tất cả các bước trên, chúng ta có thể sử dụng model để dự đoán dữ liệu.  Chúng ta cần để ý là với dữ liệu raw (một câu comment), chúng ta cần phải biến đổi dữ liệu thành dạng đã được mã hóa (tokenzise) và thành 1 chuỗi mã hóa có độ dài 250 ký tự (sequence) giống như các bước ở trên. Để làm việc này được tốt nhất, chúng ta sẽ gộp các bước này và bước dự đoán vào làm 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a672693-0e5d-466c-9c67-f0823fbe8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "## Kết hợp các layers thành kiến trúc mới\n",
    "exp_model = keras.Sequential([\n",
    "    \n",
    "    # Layer đầu tiên là biến đổi dữ liệu:\n",
    "    vectorization_layer,\n",
    "    \n",
    "    # Layer tiếp theo là layer dự đoán kết quả:\n",
    "    model\n",
    "])\n",
    "\n",
    "exp_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49325d-490c-496d-8fa7-21755450ff51",
   "metadata": {},
   "source": [
    "**Kiểm định lại model:**\n",
    "Để chắc chắn hơn, chúng ta hay kiểm định lại model trên tập test. Lần này, chúng ta chỉ cần load tập test từ folder mà thôi, bỏ qua bước biến đổi dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f298aec-6536-4857-bfe0-e57532060319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 0.3310 - accuracy: 0.8668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.326802134513855, 0.8685200214385986]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "test_ds = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory=f'{path}/test'\n",
    "    , labels = 'inferred'\n",
    ")\n",
    "\n",
    "\n",
    "# Kiểm định lại model:\n",
    "exp_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f9f4a-eaf1-492f-97b7-1f6b2736ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 640661    \n",
      "=================================================================\n",
      "Total params: 640,661\n",
      "Trainable params: 640,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Tổng hợp lại model:\n",
    "exp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13ac73-1747-4fda-aad1-eaa19965cd8a",
   "metadata": {},
   "source": [
    "Okay, sau tất cả, giờ là lúc chúng ta dự đoán:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08268b-8437-4604-a53c-32056157a4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8573272 ],\n",
       "       [0.10417002],\n",
       "       [0.38536677]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "# Thử tài dự đoán:\n",
    "inference_data = [\"This movie is great, it shows compassion and love of human for the nature.\"\n",
    "                  , \"The content is a mess, I can figure out what's going on even at the end of the movie.\"\n",
    "                  , \"The movie has both pros and cons. While we see some good acting from the main actor, however, the story line is not up to grasp.\"]\n",
    "\n",
    "exp_model.predict(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21b356-c892-4c5f-a9bf-872917e9b5c4",
   "metadata": {},
   "source": [
    "# Multi-category Classification\n",
    "> Ở phần trên, chúng ta đã phân loại cảm xúc với dữ liệu IMDB. Giờ chúng ta sẽ thử với phân loại câu hỏi của StackOverflow theo nhóm ngôn ngữ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09a45b-4502-4974-bde5-952f56c81f7c",
   "metadata": {},
   "source": [
    "## Download dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce746d14-d791-4d87-95d2-f8d146266dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ddpham/git/TFExam/data/stack_overflow_16k/stack_overflow_16k'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "path = \"/home/ddpham/git/TFExam/data/\"\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\"\n",
    "keras.utils.get_file(fname='stack_overflow_16k', origin=url, untar=True, cache_dir=path, cache_subdir='stack_overflow_16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9ddb2-f799-4cfd-8bd7-3fbf5dcee83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "path = os.path.join(os.path.dirname(path), 'stack_overflow_16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fa221-75ee-4ee1-ac43-c0ec33e61dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md', 'stack_overflow_16k.tar.gz', 'test', 'train']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra folder:\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ff53f-24ca-4a9b-b297-fd034c3d031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['java', 'javascript', 'python', 'csharp']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra subfolder:\n",
    "os.listdir(os.path.join(path, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbd23c-0a4e-485b-8992-4ae7be78d3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1636.txt',\n",
       " '467.txt',\n",
       " '174.txt',\n",
       " '1301.txt',\n",
       " '1619.txt',\n",
       " '893.txt',\n",
       " '828.txt',\n",
       " '1467.txt',\n",
       " '1032.txt',\n",
       " '146.txt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra subfolder\n",
    "os.listdir(os.path.join(path, 'train', 'python'))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539a607-02ce-4c08-b876-dd7ebd4b40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"convert a string to datetime object in blank i have a date string defined as followed:..datestr = '2011-05-01'...i want to convert this into a datetime object so i used the following code..dateobj = datetime.datetime.strptime(datestr,'%y-%m-%d').print dateobj...but what gets printed is: 2011-05-01 00:00:00. i just need 2011-05-01. what needs to be changed in my code ?..thank you\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu:\n",
    "with open(f'{path}/train/python/1636.txt') as file:\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e4ceb-7697-4045-bc35-875dfe24cf2e",
   "metadata": {},
   "source": [
    "## Tạo dữ liệu\n",
    "> Tương tự như trong bài sentiment analysis, chúng ta sẽ có các bước tạo dữ liệu tương đồng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1c67c-e481-4008-b884-56981649835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n",
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "bs = 32\n",
    "seed=345\n",
    "train_ds = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory=f'{path}/train'\n",
    "    , labels='inferred'\n",
    "    , label_mode='categorical'\n",
    "    , batch_size=bs\n",
    "    , seed=seed\n",
    "    , validation_split=0.2\n",
    "    , subset='training'\n",
    ")\n",
    "valid_ds = keras.preprocessing.text_dataset_from_directory(\n",
    "    directory=f\"{path}/train\"\n",
    "    , labels='inferred'\n",
    "    , label_mode='categorical'\n",
    "    , batch_size=bs\n",
    "    , seed=seed\n",
    "    , validation_split=0.2\n",
    "    , subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9df6ba-ca7e-47ff-9081-66bf6c9816eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " tf.Tensor(b'\"only one word of a sentence prints using replace method as my class project i have written some codes that receives a sentence and if it has a special character by checking it\\'s ascii code it replaces it with another one. but unfortunately every time it replaces and shows only first word and deletes rest of the sentence. please help me and if there\\'s a better way for this it\\'s appreciated...here\\'s my code:..import blank.util.scanner;..public class helloworld {..public static void main(string[] arg) {.    scanner scanner = new scanner(system.in);.    string s = scanner.next();.    if (s.contains(\"\"u0626\"\")) {.        string result = s.replaceall(\"\"u0626\"\", \"\"u0628\"\");.        system.out.println(result);.    }...}...}\"\\n', shape=(), dtype=string)\n",
      "Language: \n",
      " tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu:\n",
    "for text in train_ds.take(1):\n",
    "    print(\"Question: \\n\", text[0][1])\n",
    "    print(\"Language: \\n\", text[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b2dda-4969-41c3-a704-a5510260d5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csharp', 'java', 'javascript', 'python']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu\n",
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d725e-deb5-4172-b2af-4353585832f2",
   "metadata": {},
   "source": [
    "__Lưu ý:__\n",
    "Ở đây chúng ta có thể thấy dữ liệu labels đang trả về kết quả dưới dạng array 0 và 1. Trong đó index của giá trị = 1 chính là loại ngôn ngữ được hỏi của câu hỏi. Cụ thể ở đây là `javascript`. Phần lớn các dữ liệu label được trả về dưới dạng `int` (một giá trị trong chuỗi giá  trị category của labels). Việc này sẽ ảnh hưởng đến loss mà chúng ta sẽ sử dụng trong model (`int -> spatial_categorical_crossentropy`; `categorical -> categorical_crossentropy`). Nếu chúng ta muốn đổi lại label theo cách int, trong phần tạo dữ liệu dataset, chọn label_mode='int'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d65fb6-4486-4aeb-b9f0-a43c977f351e",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956dfae-2052-4bad-a113-8e8c62356627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "max_tokens = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorization_layer = keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=max_tokens\n",
    "    , standardize='lower_and_strip_punctuation'\n",
    "    , split='whitespace'\n",
    "    , output_mode='int'\n",
    "    , output_sequence_length=sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736845c-2d35-491a-b650-5eb32b89ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Tạo raw text để adapt vectorization layer:\n",
    "raw_text = []\n",
    "for _, text in train_ds.enumerate():\n",
    "    for ind in range(32):\n",
    "        raw_text.append([text[0][ind].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8938a4b-2c83-43ef-8db4-6508dc2f0bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\"queue implementation does not return first element i want to emulate a queue by using linked lists in blank. my general schema is to have a list of nodes, with two nodes that points to the first and last element of my queue. when i perform the dequeue() i want to get ride of the first element. so far what i have done is the following:..public class node {.    public object e;.    node next;..    public node(object e) {.        this.e = e;.    }.}..public class queue {.    node queuelist;.    node first, last;.    int count;..    public void enqueue(object n) {.        node temp = new node(n);.        temp.next = last;.        last = temp;.        if (queuelist == null) {.            first = temp;.        }.        count++;.        queuelist=temp;.    }..    public object dequeue() {.        node previous = last;.        node current = last.next;.        object num = null;.        if (count == 0).            system.out.println(\"\"empty queue\"\");.        else {.            while (current.next != null) {.                previous = previous.next;.                current = current.next;.            }.            num = first.e;.            first = previous;.            count--;.        }.        return num;.    }..    public void print() {.        node current = last;.        while (current != null) {.            system.out.println(current.e);.            current = current.next;.        }.    }.}...i do not want to use double linked lists, so for the dequeue() operation what i do is to traverse my list with two pointers like this:....so when the current.next points to a null, i want that previous to be the first node. the problem that i got is when i print the elements of my queue it stills prints me: 10,15,5,18, but the 18 value is not deleted. any help?..thanks\"\\n']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu\n",
    "raw_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a48c1-3dae-434b-9a4f-e9441ee31310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "vectorization_layer.adapt(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d72a1-2bd4-46d2-88fc-52f948f75062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  16   24   39    3  147    5  463   22   94  284    9    2  194   51\n",
      "    81    4   42  371    5   18   14  285    2  240    4    5    1   44\n",
      "     4   39   11   22   96    5  284    9    2  463    1  324    3   17\n",
      "     5  463  246 6783    7    1    3   44    4   33  237    4   42   14\n",
      "   240   76 1186    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 250), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# Kiểm tra dữ liệu:\n",
    "for text in valid_ds.take(1):\n",
    "    print(vectorization_layer([text[0][10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcee64e-5e12-4512-871d-01d680290f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export:\n",
    "def vectorize_text(x, y):\n",
    "    x = tf.expand_dims(x, -1)\n",
    "    return vectorization_layer(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9085beb-65b2-4c9d-b044-ad9e7d2693e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "train_ds = train_ds.map(vectorize_text)\n",
    "valid_ds = valid_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ce75b-9a57-416f-b57f-de56efd437a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2cccfd-adba-45d6-9e2f-d4cb1764ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 250), (None, 4)), types: (tf.int64, tf.float32)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5761bde-bb77-4325-9e2f-2cca56d7dd77",
   "metadata": {},
   "source": [
    "## Tạo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7c6ca-8ea1-4bfe-a841-ef1d1992b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 64)           640000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 641,384\n",
      "Trainable params: 641,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "keras.backend.clear_session()\n",
    "embedding_dim = 64\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim, input_length=sequence_length)\n",
    "    , keras.layers.GlobalMaxPooling1D()\n",
    "    , keras.layers.Dropout(.5)\n",
    "    , keras.layers.Dense(20, activation='relu')\n",
    "    , keras.layers.Dropout(.2)\n",
    "    , keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=1e-8)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56006d-2e24-4754-9f26-f0ea074fd1d0",
   "metadata": {},
   "source": [
    "### Tìm lr phù hợp\n",
    "> Chúng ta có thể kết hợp với bài học về tìm learning rate phù hợp cho bài toán của chúng ta với LearningRateScheduler trong callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef592670-e6ca-424b-9b15-ff2332441dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lambda epoch: 10e-8 * 10**(epoch/10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751be36-fc20-4e37-aa70-f51a35747c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.3890 - accuracy: 0.2539 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 2/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3875 - accuracy: 0.2538 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 3/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3882 - accuracy: 0.2428 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 4/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3890 - accuracy: 0.2428 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 5/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.3899 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 6/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3892 - accuracy: 0.2447 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 7/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.3884 - accuracy: 0.2495 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 8/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3893 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 9/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3881 - accuracy: 0.2580 - val_loss: 1.3863 - val_accuracy: 0.2556\n",
      "Epoch 10/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3873 - accuracy: 0.2479 - val_loss: 1.3862 - val_accuracy: 0.2556\n",
      "Epoch 11/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3880 - accuracy: 0.2447 - val_loss: 1.3862 - val_accuracy: 0.2556\n",
      "Epoch 12/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3887 - accuracy: 0.2510 - val_loss: 1.3862 - val_accuracy: 0.2556\n",
      "Epoch 13/150\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 1.3890 - accuracy: 0.2433 - val_loss: 1.3862 - val_accuracy: 0.2556\n",
      "Epoch 14/150\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 1.3886 - accuracy: 0.2464 - val_loss: 1.3862 - val_accuracy: 0.2556\n",
      "Epoch 15/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.3873 - accuracy: 0.2506 - val_loss: 1.3862 - val_accuracy: 0.2556\n",
      "Epoch 16/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3875 - accuracy: 0.2561 - val_loss: 1.3861 - val_accuracy: 0.2556\n",
      "Epoch 17/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.3875 - accuracy: 0.2476 - val_loss: 1.3861 - val_accuracy: 0.2562\n",
      "Epoch 18/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3884 - accuracy: 0.2500 - val_loss: 1.3861 - val_accuracy: 0.2569\n",
      "Epoch 19/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3886 - accuracy: 0.2419 - val_loss: 1.3860 - val_accuracy: 0.2569\n",
      "Epoch 20/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.3871 - accuracy: 0.2597 - val_loss: 1.3859 - val_accuracy: 0.2575\n",
      "Epoch 21/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3878 - accuracy: 0.2419 - val_loss: 1.3858 - val_accuracy: 0.2581\n",
      "Epoch 22/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3875 - accuracy: 0.2568 - val_loss: 1.3857 - val_accuracy: 0.2619\n",
      "Epoch 23/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3878 - accuracy: 0.2510 - val_loss: 1.3855 - val_accuracy: 0.2681\n",
      "Epoch 24/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.3884 - accuracy: 0.2527 - val_loss: 1.3853 - val_accuracy: 0.2800\n",
      "Epoch 25/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1.3889 - accuracy: 0.2440 - val_loss: 1.3849 - val_accuracy: 0.3131\n",
      "Epoch 26/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3871 - accuracy: 0.2519 - val_loss: 1.3844 - val_accuracy: 0.2875\n",
      "Epoch 27/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3853 - accuracy: 0.2635 - val_loss: 1.3838 - val_accuracy: 0.2781\n",
      "Epoch 28/150\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3854 - accuracy: 0.2501 - val_loss: 1.3829 - val_accuracy: 0.2969\n",
      "Epoch 29/150\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3832 - accuracy: 0.2833 - val_loss: 1.3816 - val_accuracy: 0.2981\n",
      "Epoch 30/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.3826 - accuracy: 0.2779 - val_loss: 1.3798 - val_accuracy: 0.3006\n",
      "Epoch 31/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3813 - accuracy: 0.2730 - val_loss: 1.3769 - val_accuracy: 0.3100\n",
      "Epoch 32/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.3805 - accuracy: 0.2775 - val_loss: 1.3725 - val_accuracy: 0.3169\n",
      "Epoch 33/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.3715 - accuracy: 0.3276 - val_loss: 1.3652 - val_accuracy: 0.3631\n",
      "Epoch 34/150\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 1.3673 - accuracy: 0.3255 - val_loss: 1.3518 - val_accuracy: 0.4563\n",
      "Epoch 35/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.3514 - accuracy: 0.3591 - val_loss: 1.3270 - val_accuracy: 0.5075\n",
      "Epoch 36/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.3275 - accuracy: 0.4081 - val_loss: 1.2810 - val_accuracy: 0.5875\n",
      "Epoch 37/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.2813 - accuracy: 0.4461 - val_loss: 1.1988 - val_accuracy: 0.6219\n",
      "Epoch 38/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.2050 - accuracy: 0.5007 - val_loss: 1.0842 - val_accuracy: 0.6513\n",
      "Epoch 39/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.1150 - accuracy: 0.5353 - val_loss: 0.9550 - val_accuracy: 0.6800\n",
      "Epoch 40/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.0007 - accuracy: 0.5944 - val_loss: 0.8264 - val_accuracy: 0.7088\n",
      "Epoch 41/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.9222 - accuracy: 0.6219 - val_loss: 0.7272 - val_accuracy: 0.7419\n",
      "Epoch 42/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.8355 - accuracy: 0.6634 - val_loss: 0.6503 - val_accuracy: 0.7506\n",
      "Epoch 43/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.7689 - accuracy: 0.6941 - val_loss: 0.5912 - val_accuracy: 0.7706\n",
      "Epoch 44/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.7101 - accuracy: 0.7229 - val_loss: 0.5548 - val_accuracy: 0.7906\n",
      "Epoch 45/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.6482 - accuracy: 0.7419 - val_loss: 0.5127 - val_accuracy: 0.8006\n",
      "Epoch 46/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.6020 - accuracy: 0.7725 - val_loss: 0.4970 - val_accuracy: 0.7994\n",
      "Epoch 47/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.5317 - accuracy: 0.8049 - val_loss: 0.4827 - val_accuracy: 0.8031\n",
      "Epoch 48/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4971 - accuracy: 0.8217 - val_loss: 0.4728 - val_accuracy: 0.8112\n",
      "Epoch 49/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.4639 - accuracy: 0.8365 - val_loss: 0.4745 - val_accuracy: 0.8112\n",
      "Epoch 50/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.4470 - accuracy: 0.8474 - val_loss: 0.4636 - val_accuracy: 0.8213\n",
      "Epoch 51/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.4083 - accuracy: 0.8598 - val_loss: 0.4601 - val_accuracy: 0.8181\n",
      "Epoch 52/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.3974 - accuracy: 0.8656 - val_loss: 0.4730 - val_accuracy: 0.8138\n",
      "Epoch 53/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3738 - accuracy: 0.8729 - val_loss: 0.4740 - val_accuracy: 0.8112\n",
      "Epoch 54/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3731 - accuracy: 0.8753 - val_loss: 0.5058 - val_accuracy: 0.8075\n",
      "Epoch 55/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3842 - accuracy: 0.8799 - val_loss: 0.5112 - val_accuracy: 0.7987\n",
      "Epoch 56/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3868 - accuracy: 0.8797 - val_loss: 0.5169 - val_accuracy: 0.8069\n",
      "Epoch 57/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3995 - accuracy: 0.8765 - val_loss: 0.5414 - val_accuracy: 0.8012\n",
      "Epoch 58/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4595 - accuracy: 0.8642 - val_loss: 0.5826 - val_accuracy: 0.7825\n",
      "Epoch 59/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.5133 - accuracy: 0.8463 - val_loss: 0.6470 - val_accuracy: 0.7681\n",
      "Epoch 60/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.5711 - accuracy: 0.8396 - val_loss: 0.6609 - val_accuracy: 0.7425\n",
      "Epoch 61/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.7872 - accuracy: 0.8019 - val_loss: 0.7709 - val_accuracy: 0.7494\n",
      "Epoch 62/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.0286 - accuracy: 0.7685 - val_loss: 0.8234 - val_accuracy: 0.6981\n",
      "Epoch 63/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.2130 - accuracy: 0.6891 - val_loss: 0.9172 - val_accuracy: 0.5725\n",
      "Epoch 64/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.7285 - accuracy: 0.5823 - val_loss: 1.0880 - val_accuracy: 0.4481\n",
      "Epoch 65/150\n",
      "200/200 [==============================] - 5s 22ms/step - loss: 1.5503 - accuracy: 0.4824 - val_loss: 1.3410 - val_accuracy: 0.2869\n",
      "Epoch 66/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.6993 - accuracy: 0.3452 - val_loss: 1.3905 - val_accuracy: 0.2812\n",
      "Epoch 67/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 2.2564 - accuracy: 0.3090 - val_loss: 1.4318 - val_accuracy: 0.2369\n",
      "Epoch 68/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 2.0211 - accuracy: 0.2690 - val_loss: 1.4464 - val_accuracy: 0.2375\n",
      "Epoch 69/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 2.2222 - accuracy: 0.2621 - val_loss: 1.4665 - val_accuracy: 0.2325\n",
      "Epoch 70/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 1.6464 - accuracy: 0.2504 - val_loss: 1.4735 - val_accuracy: 0.2325\n",
      "Epoch 71/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 2.1783 - accuracy: 0.2550 - val_loss: 1.4717 - val_accuracy: 0.2325\n",
      "Epoch 72/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.6960 - accuracy: 0.2500 - val_loss: 1.4541 - val_accuracy: 0.2325\n",
      "Epoch 73/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 2.1242 - accuracy: 0.2506 - val_loss: 1.4241 - val_accuracy: 0.2612\n",
      "Epoch 74/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 2.4559 - accuracy: 0.2496 - val_loss: 1.4307 - val_accuracy: 0.2612\n",
      "Epoch 75/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 4.8363 - accuracy: 0.2582 - val_loss: 1.9475 - val_accuracy: 0.2612\n",
      "Epoch 76/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 8.0047 - accuracy: 0.2503 - val_loss: 2.3655 - val_accuracy: 0.2325\n",
      "Epoch 77/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 25.9813 - accuracy: 0.2440 - val_loss: 2.5585 - val_accuracy: 0.2612\n",
      "Epoch 78/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 24.3113 - accuracy: 0.2596 - val_loss: 3.1741 - val_accuracy: 0.2562\n",
      "Epoch 79/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 31.2194 - accuracy: 0.2484 - val_loss: 8.9370 - val_accuracy: 0.2325\n",
      "Epoch 80/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 103.3568 - accuracy: 0.2499 - val_loss: 5.2841 - val_accuracy: 0.2325\n",
      "Epoch 81/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 282.4990 - accuracy: 0.2571 - val_loss: 7.0053 - val_accuracy: 0.2325\n",
      "Epoch 82/150\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 75.5524 - accuracy: 0.2483 - val_loss: 6.5087 - val_accuracy: 0.2562\n",
      "Epoch 83/150\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 2124.2481 - accuracy: 0.2483 - val_loss: 9.8038 - val_accuracy: 0.2325\n",
      "Epoch 84/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 1108.7577 - accuracy: 0.2465 - val_loss: 16.8014 - val_accuracy: 0.2612\n",
      "Epoch 85/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 4004.2783 - accuracy: 0.2641 - val_loss: 23.4077 - val_accuracy: 0.2500\n",
      "Epoch 86/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 7851.1577 - accuracy: 0.2494 - val_loss: 30.4793 - val_accuracy: 0.2612\n",
      "Epoch 87/150\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 195298.3919 - accuracy: 0.2579 - val_loss: 54.7869 - val_accuracy: 0.2500\n",
      "Epoch 88/150\n",
      "200/200 [==============================] - 6s 29ms/step - loss: 8825.3665 - accuracy: 0.2449 - val_loss: 32.8042 - val_accuracy: 0.2612\n",
      "Epoch 89/150\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 12713.9272 - accuracy: 0.2591 - val_loss: 53.0983 - val_accuracy: 0.2612\n",
      "Epoch 90/150\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 209694.9500 - accuracy: 0.2502 - val_loss: 32.4123 - val_accuracy: 0.2500\n",
      "Epoch 91/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 2264.5257 - accuracy: 0.2444 - val_loss: 52.9736 - val_accuracy: 0.2562\n",
      "Epoch 92/150\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 266.0005 - accuracy: 0.2548 - val_loss: 137.4829 - val_accuracy: 0.2612\n",
      "Epoch 93/150\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 77556.6300 - accuracy: 0.2566 - val_loss: 193.1414 - val_accuracy: 0.2612\n",
      "Epoch 94/150\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 1665161.6410 - accuracy: 0.2532 - val_loss: 184.1158 - val_accuracy: 0.2325\n",
      "Epoch 95/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 191767.7135 - accuracy: 0.2515 - val_loss: 37.9529 - val_accuracy: 0.2325\n",
      "Epoch 96/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1249328.1552 - accuracy: 0.2584 - val_loss: 66.4789 - val_accuracy: 0.2612\n",
      "Epoch 97/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 27296495.4278 - accuracy: 0.2509 - val_loss: 296.6837 - val_accuracy: 0.2562\n",
      "Epoch 98/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 718909.8733 - accuracy: 0.2456 - val_loss: 246.1945 - val_accuracy: 0.2500\n",
      "Epoch 99/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 12429894.3759 - accuracy: 0.2453 - val_loss: 733.2256 - val_accuracy: 0.2612\n",
      "Epoch 100/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 47527217.1624 - accuracy: 0.2539 - val_loss: 526.2153 - val_accuracy: 0.2562\n",
      "Epoch 101/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 361601927.8719 - accuracy: 0.2504 - val_loss: 420.9090 - val_accuracy: 0.2612\n",
      "Epoch 102/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1262296935.4100 - accuracy: 0.2491 - val_loss: 1972.5334 - val_accuracy: 0.2325\n",
      "Epoch 103/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 544926677.4198 - accuracy: 0.2463 - val_loss: 944.5361 - val_accuracy: 0.2325\n",
      "Epoch 104/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 543280911.0278 - accuracy: 0.2597 - val_loss: 554.7307 - val_accuracy: 0.2500\n",
      "Epoch 105/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 23671872.7143 - accuracy: 0.2481 - val_loss: 1994.0753 - val_accuracy: 0.2612\n",
      "Epoch 106/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1296015176.2343 - accuracy: 0.2463 - val_loss: 2965.7263 - val_accuracy: 0.2562\n",
      "Epoch 107/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 215765058.9070 - accuracy: 0.2501 - val_loss: 2668.6912 - val_accuracy: 0.2612\n",
      "Epoch 108/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 4250.1409 - accuracy: 0.2554 - val_loss: 6595.6533 - val_accuracy: 0.2325\n",
      "Epoch 109/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1757947712.3313 - accuracy: 0.2444 - val_loss: 3789.2715 - val_accuracy: 0.2612\n",
      "Epoch 110/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 2511109274.0101 - accuracy: 0.2575 - val_loss: 4427.9849 - val_accuracy: 0.2562\n",
      "Epoch 111/150\n",
      "200/200 [==============================] - 4s 19ms/step - loss: 216418849974.5326 - accuracy: 0.2536 - val_loss: 3237.4978 - val_accuracy: 0.2500\n",
      "Epoch 112/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 181142932077.2144 - accuracy: 0.2419 - val_loss: 16133.6514 - val_accuracy: 0.2612\n",
      "Epoch 113/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 13578.8413 - accuracy: 0.2538 - val_loss: 13063.3779 - val_accuracy: 0.2562\n",
      "Epoch 114/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 5647008235.4701 - accuracy: 0.2480 - val_loss: 21004.0918 - val_accuracy: 0.2612\n",
      "Epoch 115/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 21689.0936 - accuracy: 0.2480 - val_loss: 23508.6875 - val_accuracy: 0.2325\n",
      "Epoch 116/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 51436941073.0047 - accuracy: 0.2525 - val_loss: 32497.9102 - val_accuracy: 0.2612\n",
      "Epoch 117/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 3446192053707.5151 - accuracy: 0.2633 - val_loss: 56810.4609 - val_accuracy: 0.2612\n",
      "Epoch 118/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 8313205617208.6426 - accuracy: 0.2522 - val_loss: 43479.9102 - val_accuracy: 0.2562\n",
      "Epoch 119/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 4596589006305.6484 - accuracy: 0.2544 - val_loss: 45215.5703 - val_accuracy: 0.2612\n",
      "Epoch 120/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 66975.2127 - accuracy: 0.2577 - val_loss: 127998.5312 - val_accuracy: 0.2325\n",
      "Epoch 121/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 8583583231696.8857 - accuracy: 0.2417 - val_loss: 75921.2656 - val_accuracy: 0.2325\n",
      "Epoch 122/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 12976368360681.1875 - accuracy: 0.2568 - val_loss: 53526.1133 - val_accuracy: 0.2562\n",
      "Epoch 123/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 252113603465167.2188 - accuracy: 0.2544 - val_loss: 97891.6094 - val_accuracy: 0.2612\n",
      "Epoch 124/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 8618876450087.3369 - accuracy: 0.2472 - val_loss: 215239.5781 - val_accuracy: 0.2562\n",
      "Epoch 125/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 34011869632564.0547 - accuracy: 0.2503 - val_loss: 174555.7656 - val_accuracy: 0.2612\n",
      "Epoch 126/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 111043301289097.8750 - accuracy: 0.2539 - val_loss: 428422.6250 - val_accuracy: 0.2325\n",
      "Epoch 127/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 2983118343710957.0000 - accuracy: 0.2472 - val_loss: 388123.4688 - val_accuracy: 0.2562\n",
      "Epoch 128/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 7732367736396028.0000 - accuracy: 0.2515 - val_loss: 244563.9531 - val_accuracy: 0.2612\n",
      "Epoch 129/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1041055176138973.1250 - accuracy: 0.2494 - val_loss: 830817.6875 - val_accuracy: 0.2612\n",
      "Epoch 130/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 49399651841565720.0000 - accuracy: 0.2440 - val_loss: 510379.2500 - val_accuracy: 0.2325\n",
      "Epoch 131/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 34824923547467572.0000 - accuracy: 0.2609 - val_loss: 686255.6250 - val_accuracy: 0.2612\n",
      "Epoch 132/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 567671997771444480.0000 - accuracy: 0.2475 - val_loss: 1965961.8750 - val_accuracy: 0.2325\n",
      "Epoch 133/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 48088684472999336.0000 - accuracy: 0.2447 - val_loss: 1487374.8750 - val_accuracy: 0.2612\n",
      "Epoch 134/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1665706.0118 - accuracy: 0.2653 - val_loss: 1127788.6250 - val_accuracy: 0.2562\n",
      "Epoch 135/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 640142113167795072.0000 - accuracy: 0.2486 - val_loss: 1928770.2500 - val_accuracy: 0.2612\n",
      "Epoch 136/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 8904876041747126.0000 - accuracy: 0.2505 - val_loss: 3557011.7500 - val_accuracy: 0.2562\n",
      "Epoch 137/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 7041636984049513472.0000 - accuracy: 0.2596 - val_loss: 3449108.5000 - val_accuracy: 0.2612\n",
      "Epoch 138/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 730800788590212480.0000 - accuracy: 0.2543 - val_loss: 7503926.5000 - val_accuracy: 0.2325\n",
      "Epoch 139/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 2378633299545459712.0000 - accuracy: 0.2355 - val_loss: 4441614.5000 - val_accuracy: 0.2612\n",
      "Epoch 140/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 6580513.6816 - accuracy: 0.2668 - val_loss: 4469662.0000 - val_accuracy: 0.2562\n",
      "Epoch 141/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 558707129455646592.0000 - accuracy: 0.2519 - val_loss: 4170899.0000 - val_accuracy: 0.2612\n",
      "Epoch 142/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 114571412093446979584.0000 - accuracy: 0.2513 - val_loss: 18171924.0000 - val_accuracy: 0.2612\n",
      "Epoch 143/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 1756245479024373268480.0000 - accuracy: 0.2553 - val_loss: 9585802.0000 - val_accuracy: 0.2562\n",
      "Epoch 144/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 6170676498893575168.0000 - accuracy: 0.2494 - val_loss: 19744196.0000 - val_accuracy: 0.2612\n",
      "Epoch 145/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 15138521814641827840.0000 - accuracy: 0.2523 - val_loss: 43574032.0000 - val_accuracy: 0.2325\n",
      "Epoch 146/150\n",
      "200/200 [==============================] - 4s 19ms/step - loss: 6991209539146638336.0000 - accuracy: 0.2449 - val_loss: 34273532.0000 - val_accuracy: 0.2325\n",
      "Epoch 147/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 33768187.4826 - accuracy: 0.2597 - val_loss: 12654697.0000 - val_accuracy: 0.2325\n",
      "Epoch 148/150\n",
      "200/200 [==============================] - 4s 18ms/step - loss: 899546095350055174144.0000 - accuracy: 0.2504 - val_loss: 56149516.0000 - val_accuracy: 0.2612\n",
      "Epoch 149/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 53868071.8806 - accuracy: 0.2510 - val_loss: 59646644.0000 - val_accuracy: 0.2562\n",
      "Epoch 150/150\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 14549249454249909157888.0000 - accuracy: 0.2570 - val_loss: 68982944.0000 - val_accuracy: 0.2612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33c033ec70>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "epochs=150\n",
    "model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c75fe-9732-4ffb-9e03-e03cd95a9e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "# Vẽ đồ thị learning rate và loss:\n",
    "history = model.history\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-8, 1e-1, 0, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6012c-cdb3-4167-a83d-4ca3adc7f387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 64)           640000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 641,384\n",
      "Trainable params: 641,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "learning_rate = 5e-3\n",
    "keras.backend.clear_session()\n",
    "embedding_dim = 64\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim, input_length=sequence_length)\n",
    "    , keras.layers.GlobalMaxPooling1D()\n",
    "    , keras.layers.Dropout(.5)\n",
    "    , keras.layers.Dense(20, activation='relu')\n",
    "    , keras.layers.Dropout(.2)\n",
    "    , keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195ce5d-fd42-4543-aadd-ad111532e94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 1.2872 - accuracy: 0.3701 - val_loss: 0.8098 - val_accuracy: 0.6538\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.9219 - accuracy: 0.6140 - val_loss: 0.6482 - val_accuracy: 0.7337\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.7677 - accuracy: 0.6880 - val_loss: 0.5827 - val_accuracy: 0.7550\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.6719 - accuracy: 0.7359 - val_loss: 0.5480 - val_accuracy: 0.7850\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.6126 - accuracy: 0.7654 - val_loss: 0.5173 - val_accuracy: 0.7819\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.5742 - accuracy: 0.7894 - val_loss: 0.5016 - val_accuracy: 0.7844\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4977 - accuracy: 0.8167 - val_loss: 0.4937 - val_accuracy: 0.7944\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4631 - accuracy: 0.8340 - val_loss: 0.4952 - val_accuracy: 0.7975\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.4278 - accuracy: 0.8540 - val_loss: 0.4857 - val_accuracy: 0.8012\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.4013 - accuracy: 0.8656 - val_loss: 0.4877 - val_accuracy: 0.8062\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3753 - accuracy: 0.8732 - val_loss: 0.4898 - val_accuracy: 0.8056\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3441 - accuracy: 0.8884 - val_loss: 0.4972 - val_accuracy: 0.8012\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3175 - accuracy: 0.8975 - val_loss: 0.4975 - val_accuracy: 0.8112\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3229 - accuracy: 0.8975 - val_loss: 0.5019 - val_accuracy: 0.8094\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2817 - accuracy: 0.9123 - val_loss: 0.5150 - val_accuracy: 0.8081\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2695 - accuracy: 0.9108 - val_loss: 0.5257 - val_accuracy: 0.8069\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2369 - accuracy: 0.9165 - val_loss: 0.5311 - val_accuracy: 0.8019\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2423 - accuracy: 0.9201 - val_loss: 0.5354 - val_accuracy: 0.8006\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2456 - accuracy: 0.9207 - val_loss: 0.5402 - val_accuracy: 0.8006\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2592 - accuracy: 0.9241 - val_loss: 0.5469 - val_accuracy: 0.8019\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2087 - accuracy: 0.9336 - val_loss: 0.5622 - val_accuracy: 0.8019\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2081 - accuracy: 0.9361 - val_loss: 0.5693 - val_accuracy: 0.7969\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2049 - accuracy: 0.9340 - val_loss: 0.5784 - val_accuracy: 0.7987\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2089 - accuracy: 0.9377 - val_loss: 0.5791 - val_accuracy: 0.8037\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1951 - accuracy: 0.9459 - val_loss: 0.5838 - val_accuracy: 0.7962\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2141 - accuracy: 0.9370 - val_loss: 0.5828 - val_accuracy: 0.8000\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1956 - accuracy: 0.9465 - val_loss: 0.6227 - val_accuracy: 0.7994\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1767 - accuracy: 0.9468 - val_loss: 0.6135 - val_accuracy: 0.8025\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.1802 - accuracy: 0.9522 - val_loss: 0.6315 - val_accuracy: 0.7950\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.1724 - accuracy: 0.9505 - val_loss: 0.6392 - val_accuracy: 0.7950\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.1779 - accuracy: 0.9449 - val_loss: 0.6550 - val_accuracy: 0.7944\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1757 - accuracy: 0.9493 - val_loss: 0.6808 - val_accuracy: 0.7969\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1646 - accuracy: 0.9506 - val_loss: 0.6742 - val_accuracy: 0.7987\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1579 - accuracy: 0.9552 - val_loss: 0.6538 - val_accuracy: 0.7975\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1527 - accuracy: 0.9539 - val_loss: 0.6597 - val_accuracy: 0.7931\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1496 - accuracy: 0.9581 - val_loss: 0.6882 - val_accuracy: 0.7937\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1490 - accuracy: 0.9590 - val_loss: 0.6717 - val_accuracy: 0.7956\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1426 - accuracy: 0.9596 - val_loss: 0.7179 - val_accuracy: 0.7944\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1751 - accuracy: 0.9532 - val_loss: 0.7039 - val_accuracy: 0.7975\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1531 - accuracy: 0.9559 - val_loss: 0.7208 - val_accuracy: 0.7900\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1430 - accuracy: 0.9582 - val_loss: 0.7283 - val_accuracy: 0.7937\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1439 - accuracy: 0.9610 - val_loss: 0.7373 - val_accuracy: 0.7912\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1415 - accuracy: 0.9583 - val_loss: 0.7656 - val_accuracy: 0.7869\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1263 - accuracy: 0.9650 - val_loss: 0.8018 - val_accuracy: 0.7944\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1143 - accuracy: 0.9653 - val_loss: 0.8056 - val_accuracy: 0.7944\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1441 - accuracy: 0.9610 - val_loss: 0.7656 - val_accuracy: 0.7912\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1254 - accuracy: 0.9596 - val_loss: 0.7395 - val_accuracy: 0.7975\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1283 - accuracy: 0.9590 - val_loss: 0.7923 - val_accuracy: 0.7981\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1220 - accuracy: 0.9666 - val_loss: 0.7914 - val_accuracy: 0.7944\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1176 - accuracy: 0.9697 - val_loss: 0.8064 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33d80616d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "epochs=50\n",
    "model.fit(train_ds, epochs=epochs, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d20f7e-d955-4bb0-a211-0b018b695c96",
   "metadata": {},
   "source": [
    "Model của chúng ta ở thời điểm này là khá overfit. Một trong nhưng cách chúng ta có thể làm là thêm dropout layer, upgrade model với model tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18e59f-f538-413f-b1f0-e0f0945dc36b",
   "metadata": {},
   "source": [
    "## Nâng cấp model vs RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a6e289-3ad1-4fd9-9ec2-0c71983e560b",
   "metadata": {},
   "source": [
    "### Thêm 1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21824751-2626-47ce-8d67-8de3a6dc7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 64)           640000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 666,216\n",
      "Trainable params: 666,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Xóa thông tin các model cũ:\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Tạo input:\n",
    "inputs = keras.Input(shape=(250))\n",
    "\n",
    "# Tạo embeding:\n",
    "embedding_dim = 64\n",
    "embeding = keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n",
    "\n",
    "# Tạo Bidirectional LSTM:\n",
    "lstm = keras.layers.Bidirectional(keras.layers.LSTM(32))(embeding)\n",
    "\n",
    "# Tạo dropout:\n",
    "dropout = keras.layers.Dropout(0.2)(lstm)\n",
    "\n",
    "# Tạo dense:\n",
    "dense = keras.layers.Dense(20, activation='relu')(dropout)\n",
    "\n",
    "# Tạo prediction:\n",
    "prediction = keras.layers.Dense(4, activation='softmax')(dense)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=prediction)\n",
    "\n",
    "# Tạo loss:\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Tạo lr scheduler:\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lambda epoch: 10e-8 * 10 ** (epoch/10))\n",
    "\n",
    "# Tạo optimizer:\n",
    "optimizer = keras.optimizers.Adam(learning_rate=10e-8)\n",
    "\n",
    "# Compile model:\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a474142-e73c-41b2-a6e2-58ba58d467c7",
   "metadata": {},
   "source": [
    "#### Tìm lr phù hợp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd996b8-90bf-4d75-a33b-57fea597b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "200/200 [==============================] - 77s 344ms/step - loss: 1.3863 - accuracy: 0.2459 - val_loss: 1.3868 - val_accuracy: 0.2469\n",
      "Epoch 2/150\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 1.3862 - accuracy: 0.2457 - val_loss: 1.3868 - val_accuracy: 0.2475\n",
      "Epoch 3/150\n",
      "200/200 [==============================] - 70s 350ms/step - loss: 1.3863 - accuracy: 0.2547 - val_loss: 1.3868 - val_accuracy: 0.2481\n",
      "Epoch 4/150\n",
      "200/200 [==============================] - 65s 326ms/step - loss: 1.3862 - accuracy: 0.2533 - val_loss: 1.3868 - val_accuracy: 0.2469\n",
      "Epoch 5/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 1.3863 - accuracy: 0.2595 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 6/150\n",
      "200/200 [==============================] - 65s 324ms/step - loss: 1.3862 - accuracy: 0.2603 - val_loss: 1.3868 - val_accuracy: 0.2506\n",
      "Epoch 7/150\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 1.3863 - accuracy: 0.2535 - val_loss: 1.3868 - val_accuracy: 0.2519\n",
      "Epoch 8/150\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.3860 - accuracy: 0.2616 - val_loss: 1.3867 - val_accuracy: 0.2512\n",
      "Epoch 9/150\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.3861 - accuracy: 0.2585 - val_loss: 1.3867 - val_accuracy: 0.2544\n",
      "Epoch 10/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.3859 - accuracy: 0.2645 - val_loss: 1.3867 - val_accuracy: 0.2531\n",
      "Epoch 11/150\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.3861 - accuracy: 0.2689 - val_loss: 1.3867 - val_accuracy: 0.2531\n",
      "Epoch 12/150\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 1.3862 - accuracy: 0.2568 - val_loss: 1.3867 - val_accuracy: 0.2544\n",
      "Epoch 13/150\n",
      "200/200 [==============================] - 63s 314ms/step - loss: 1.3861 - accuracy: 0.2612 - val_loss: 1.3866 - val_accuracy: 0.2556\n",
      "Epoch 14/150\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 1.3860 - accuracy: 0.2567 - val_loss: 1.3866 - val_accuracy: 0.2562\n",
      "Epoch 15/150\n",
      "200/200 [==============================] - 65s 327ms/step - loss: 1.3861 - accuracy: 0.2471 - val_loss: 1.3865 - val_accuracy: 0.2587\n",
      "Epoch 16/150\n",
      "200/200 [==============================] - 64s 321ms/step - loss: 1.3859 - accuracy: 0.2815 - val_loss: 1.3865 - val_accuracy: 0.2594\n",
      "Epoch 17/150\n",
      "200/200 [==============================] - 61s 304ms/step - loss: 1.3858 - accuracy: 0.2669 - val_loss: 1.3864 - val_accuracy: 0.2594\n",
      "Epoch 18/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 1.3860 - accuracy: 0.2628 - val_loss: 1.3863 - val_accuracy: 0.2656\n",
      "Epoch 19/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.3857 - accuracy: 0.2801 - val_loss: 1.3861 - val_accuracy: 0.2713\n",
      "Epoch 20/150\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1.3856 - accuracy: 0.2746 - val_loss: 1.3860 - val_accuracy: 0.2713\n",
      "Epoch 21/150\n",
      "200/200 [==============================] - 47s 238ms/step - loss: 1.3855 - accuracy: 0.2862 - val_loss: 1.3858 - val_accuracy: 0.2756\n",
      "Epoch 22/150\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 1.3852 - accuracy: 0.2853 - val_loss: 1.3856 - val_accuracy: 0.2881\n",
      "Epoch 23/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 1.3849 - accuracy: 0.2954 - val_loss: 1.3853 - val_accuracy: 0.3056\n",
      "Epoch 24/150\n",
      "200/200 [==============================] - 65s 326ms/step - loss: 1.3843 - accuracy: 0.3035 - val_loss: 1.3849 - val_accuracy: 0.3269\n",
      "Epoch 25/150\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 1.3834 - accuracy: 0.3392 - val_loss: 1.3839 - val_accuracy: 0.3419\n",
      "Epoch 26/150\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 1.3821 - accuracy: 0.3519 - val_loss: 1.3820 - val_accuracy: 0.3606\n",
      "Epoch 27/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 1.3782 - accuracy: 0.4016 - val_loss: 1.3660 - val_accuracy: 0.4019\n",
      "Epoch 28/150\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 1.3148 - accuracy: 0.4303 - val_loss: 1.2145 - val_accuracy: 0.4506\n",
      "Epoch 29/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.1704 - accuracy: 0.4641 - val_loss: 1.1345 - val_accuracy: 0.4481\n",
      "Epoch 30/150\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1.0876 - accuracy: 0.4957 - val_loss: 1.0927 - val_accuracy: 0.4731\n",
      "Epoch 31/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.0805 - accuracy: 0.4930 - val_loss: 1.0241 - val_accuracy: 0.5294\n",
      "Epoch 32/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.9144 - accuracy: 0.5961 - val_loss: 0.9345 - val_accuracy: 0.5981\n",
      "Epoch 33/150\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 0.8093 - accuracy: 0.6685 - val_loss: 1.0231 - val_accuracy: 0.5794\n",
      "Epoch 34/150\n",
      "200/200 [==============================] - 56s 281ms/step - loss: 0.7247 - accuracy: 0.7169 - val_loss: 0.9759 - val_accuracy: 0.6306\n",
      "Epoch 35/150\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 0.6624 - accuracy: 0.7541 - val_loss: 1.0049 - val_accuracy: 0.6281\n",
      "Epoch 36/150\n",
      "200/200 [==============================] - 65s 325ms/step - loss: 0.5983 - accuracy: 0.7828 - val_loss: 1.0051 - val_accuracy: 0.6406\n",
      "Epoch 37/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 0.5347 - accuracy: 0.8167 - val_loss: 0.9116 - val_accuracy: 0.6681\n",
      "Epoch 38/150\n",
      "200/200 [==============================] - 65s 323ms/step - loss: 0.5234 - accuracy: 0.7985 - val_loss: 1.0141 - val_accuracy: 0.6637\n",
      "Epoch 39/150\n",
      "200/200 [==============================] - 52s 261ms/step - loss: 0.4446 - accuracy: 0.8521 - val_loss: 0.9289 - val_accuracy: 0.6869\n",
      "Epoch 40/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.7332 - accuracy: 0.7717 - val_loss: 0.8984 - val_accuracy: 0.6750\n",
      "Epoch 41/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.4279 - accuracy: 0.8476 - val_loss: 0.9347 - val_accuracy: 0.7044\n",
      "Epoch 42/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.3099 - accuracy: 0.9051 - val_loss: 1.0363 - val_accuracy: 0.6969\n",
      "Epoch 43/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.2367 - accuracy: 0.9189 - val_loss: 1.0360 - val_accuracy: 0.7025\n",
      "Epoch 44/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.2393 - accuracy: 0.9183 - val_loss: 0.9757 - val_accuracy: 0.7244\n",
      "Epoch 45/150\n",
      "200/200 [==============================] - 60s 302ms/step - loss: 0.2314 - accuracy: 0.9253 - val_loss: 0.9731 - val_accuracy: 0.6919\n",
      "Epoch 46/150\n",
      "200/200 [==============================] - 65s 324ms/step - loss: 0.2881 - accuracy: 0.9080 - val_loss: 1.0336 - val_accuracy: 0.6781\n",
      "Epoch 47/150\n",
      "200/200 [==============================] - 64s 321ms/step - loss: 0.3380 - accuracy: 0.8943 - val_loss: 1.0497 - val_accuracy: 0.6781\n",
      "Epoch 48/150\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 0.4224 - accuracy: 0.8660 - val_loss: 1.1090 - val_accuracy: 0.6831\n",
      "Epoch 49/150\n",
      "200/200 [==============================] - 63s 314ms/step - loss: 0.3482 - accuracy: 0.8968 - val_loss: 1.0921 - val_accuracy: 0.6881\n",
      "Epoch 50/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.4380 - accuracy: 0.8531 - val_loss: 1.0855 - val_accuracy: 0.6850\n",
      "Epoch 51/150\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.4881 - accuracy: 0.8432 - val_loss: 1.0418 - val_accuracy: 0.6919\n",
      "Epoch 52/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.3099 - accuracy: 0.9025 - val_loss: 1.0026 - val_accuracy: 0.6637\n",
      "Epoch 53/150\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 0.3604 - accuracy: 0.8810 - val_loss: 0.8879 - val_accuracy: 0.6850\n",
      "Epoch 54/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 0.3175 - accuracy: 0.8997 - val_loss: 1.1062 - val_accuracy: 0.6756\n",
      "Epoch 55/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.2940 - accuracy: 0.9053 - val_loss: 1.1631 - val_accuracy: 0.6963\n",
      "Epoch 56/150\n",
      "200/200 [==============================] - 64s 321ms/step - loss: 0.2628 - accuracy: 0.9165 - val_loss: 0.9996 - val_accuracy: 0.7163\n",
      "Epoch 57/150\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 0.4262 - accuracy: 0.8681 - val_loss: 1.0334 - val_accuracy: 0.6406\n",
      "Epoch 58/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 0.7804 - accuracy: 0.7237 - val_loss: 1.2798 - val_accuracy: 0.5013\n",
      "Epoch 59/150\n",
      "200/200 [==============================] - 65s 324ms/step - loss: 1.0890 - accuracy: 0.5662 - val_loss: 1.3421 - val_accuracy: 0.4306\n",
      "Epoch 60/150\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 1.2535 - accuracy: 0.4570 - val_loss: 1.3239 - val_accuracy: 0.3663\n",
      "Epoch 61/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 1.3094 - accuracy: 0.3810 - val_loss: 1.3893 - val_accuracy: 0.3125\n",
      "Epoch 62/150\n",
      "200/200 [==============================] - 49s 248ms/step - loss: 1.3595 - accuracy: 0.3364 - val_loss: 1.3949 - val_accuracy: 0.2681\n",
      "Epoch 63/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 1.4456 - accuracy: 0.2666 - val_loss: 1.4528 - val_accuracy: 0.2612\n",
      "Epoch 64/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 1.7983 - accuracy: 0.2446 - val_loss: 1.4108 - val_accuracy: 0.2606\n",
      "Epoch 65/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1.4606 - accuracy: 0.2504 - val_loss: 1.3949 - val_accuracy: 0.2512\n",
      "Epoch 66/150\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 1.4682 - accuracy: 0.2512 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 67/150\n",
      "200/200 [==============================] - 67s 337ms/step - loss: 1.4994 - accuracy: 0.2509 - val_loss: 1.3919 - val_accuracy: 0.2525\n",
      "Epoch 68/150\n",
      "200/200 [==============================] - 65s 325ms/step - loss: 2.0355 - accuracy: 0.2471 - val_loss: 1.5343 - val_accuracy: 0.2313\n",
      "Epoch 69/150\n",
      "200/200 [==============================] - 65s 326ms/step - loss: 3.5301 - accuracy: 0.2491 - val_loss: 4.0771 - val_accuracy: 0.2319\n",
      "Epoch 70/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 4.7349 - accuracy: 0.2617 - val_loss: 4.3593 - val_accuracy: 0.2313\n",
      "Epoch 71/150\n",
      "200/200 [==============================] - 53s 264ms/step - loss: 6.2963 - accuracy: 0.2466 - val_loss: 1.5980 - val_accuracy: 0.2319\n",
      "Epoch 72/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 5.2335 - accuracy: 0.2490 - val_loss: 1.4101 - val_accuracy: 0.2506\n",
      "Epoch 73/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 4.3889 - accuracy: 0.2476 - val_loss: 1.9305 - val_accuracy: 0.2512\n",
      "Epoch 74/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 4.1803 - accuracy: 0.2463 - val_loss: 2.0111 - val_accuracy: 0.2325\n",
      "Epoch 75/150\n",
      "200/200 [==============================] - 50s 248ms/step - loss: 6.0706 - accuracy: 0.2452 - val_loss: 11.1625 - val_accuracy: 0.2606\n",
      "Epoch 76/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 38.1676 - accuracy: 0.2414 - val_loss: 32.6004 - val_accuracy: 0.2569\n",
      "Epoch 77/150\n",
      "200/200 [==============================] - 62s 308ms/step - loss: 102.0430 - accuracy: 0.2474 - val_loss: 51.7163 - val_accuracy: 0.2625\n",
      "Epoch 78/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 76.5254 - accuracy: 0.2568 - val_loss: 22.5740 - val_accuracy: 0.2612\n",
      "Epoch 79/150\n",
      "200/200 [==============================] - 65s 327ms/step - loss: 107.6059 - accuracy: 0.2542 - val_loss: 22.3802 - val_accuracy: 0.2619\n",
      "Epoch 80/150\n",
      "200/200 [==============================] - 66s 328ms/step - loss: 80.1095 - accuracy: 0.2414 - val_loss: 59.5391 - val_accuracy: 0.2631\n",
      "Epoch 81/150\n",
      "200/200 [==============================] - 62s 310ms/step - loss: 259.0219 - accuracy: 0.2456 - val_loss: 156.3189 - val_accuracy: 0.2525\n",
      "Epoch 82/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 424.7253 - accuracy: 0.2531 - val_loss: 118.1519 - val_accuracy: 0.2606\n",
      "Epoch 83/150\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 1471.4416 - accuracy: 0.2536 - val_loss: 246.8275 - val_accuracy: 0.2500\n",
      "Epoch 84/150\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 1412.3331 - accuracy: 0.2336 - val_loss: 1263.4235 - val_accuracy: 0.2544\n",
      "Epoch 85/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 4608.6654 - accuracy: 0.2361 - val_loss: 47.9597 - val_accuracy: 0.2569\n",
      "Epoch 86/150\n",
      "200/200 [==============================] - 50s 250ms/step - loss: 1987.6416 - accuracy: 0.2520 - val_loss: 68.5522 - val_accuracy: 0.2562\n",
      "Epoch 87/150\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 3531.3351 - accuracy: 0.2499 - val_loss: 1657.4113 - val_accuracy: 0.2306\n",
      "Epoch 88/150\n",
      "200/200 [==============================] - 68s 341ms/step - loss: 4695.4877 - accuracy: 0.2570 - val_loss: 812.2648 - val_accuracy: 0.2612\n",
      "Epoch 89/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 3288.0834 - accuracy: 0.2394 - val_loss: 821.4874 - val_accuracy: 0.2319\n",
      "Epoch 90/150\n",
      "200/200 [==============================] - 66s 331ms/step - loss: 33205.8763 - accuracy: 0.2495 - val_loss: 24347.3594 - val_accuracy: 0.2306\n",
      "Epoch 91/150\n",
      "200/200 [==============================] - 65s 327ms/step - loss: 35566.7539 - accuracy: 0.2537 - val_loss: 11271.9814 - val_accuracy: 0.2612\n",
      "Epoch 92/150\n",
      "200/200 [==============================] - 56s 279ms/step - loss: 55093.8645 - accuracy: 0.2635 - val_loss: 44147.5898 - val_accuracy: 0.2625\n",
      "Epoch 93/150\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 95619.5254 - accuracy: 0.2499 - val_loss: 26108.5898 - val_accuracy: 0.2562\n",
      "Epoch 94/150\n",
      "200/200 [==============================] - 49s 246ms/step - loss: 84578.9311 - accuracy: 0.2454 - val_loss: 103806.2109 - val_accuracy: 0.2556\n",
      "Epoch 95/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 76181.9149 - accuracy: 0.2548 - val_loss: 9549.7578 - val_accuracy: 0.2556\n",
      "Epoch 96/150\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 332822.7736 - accuracy: 0.2600 - val_loss: 35085.8281 - val_accuracy: 0.2325\n",
      "Epoch 97/150\n",
      "200/200 [==============================] - 50s 251ms/step - loss: 424655.5409 - accuracy: 0.2600 - val_loss: 185682.2969 - val_accuracy: 0.2488\n",
      "Epoch 98/150\n",
      "200/200 [==============================] - 58s 292ms/step - loss: 1012212.9278 - accuracy: 0.2519 - val_loss: 82162.2031 - val_accuracy: 0.2331\n",
      "Epoch 99/150\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 579222.7690 - accuracy: 0.2475 - val_loss: 114952.7109 - val_accuracy: 0.2606\n",
      "Epoch 100/150\n",
      "200/200 [==============================] - 66s 331ms/step - loss: 2927009.4829 - accuracy: 0.2525 - val_loss: 377363.6250 - val_accuracy: 0.2562\n",
      "Epoch 101/150\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 1185258.5046 - accuracy: 0.2550 - val_loss: 234241.7812 - val_accuracy: 0.2319\n",
      "Epoch 102/150\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 1150935.6623 - accuracy: 0.2519 - val_loss: 234536.5938 - val_accuracy: 0.2500\n",
      "Epoch 103/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 973500.4057 - accuracy: 0.2356 - val_loss: 162851.1875 - val_accuracy: 0.2562\n",
      "Epoch 104/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 6069049.9098 - accuracy: 0.2527 - val_loss: 634467.0000 - val_accuracy: 0.2325\n",
      "Epoch 105/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 12831120.4455 - accuracy: 0.2421 - val_loss: 1767548.5000 - val_accuracy: 0.2506\n",
      "Epoch 106/150\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 55028931.5607 - accuracy: 0.2489 - val_loss: 46666136.0000 - val_accuracy: 0.2569\n",
      "Epoch 107/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 125081295.9281 - accuracy: 0.2534 - val_loss: 1246782.3750 - val_accuracy: 0.2606\n",
      "Epoch 108/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 73549016.5202 - accuracy: 0.2564 - val_loss: 11161037.0000 - val_accuracy: 0.2319\n",
      "Epoch 109/150\n",
      "200/200 [==============================] - 60s 303ms/step - loss: 159909739.7571 - accuracy: 0.2448 - val_loss: 78783568.0000 - val_accuracy: 0.2319\n",
      "Epoch 110/150\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 148112678.7583 - accuracy: 0.2447 - val_loss: 76596616.0000 - val_accuracy: 0.2338\n",
      "Epoch 111/150\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 159038999.8345 - accuracy: 0.2401 - val_loss: 97545992.0000 - val_accuracy: 0.2556\n",
      "Epoch 112/150\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 359014156.5071 - accuracy: 0.2469 - val_loss: 798784960.0000 - val_accuracy: 0.2475\n",
      "Epoch 113/150\n",
      "200/200 [==============================] - 62s 312ms/step - loss: 1483116492.2772 - accuracy: 0.2569 - val_loss: 45270716.0000 - val_accuracy: 0.2325\n",
      "Epoch 114/150\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 1564655835.2103 - accuracy: 0.2567 - val_loss: 231542368.0000 - val_accuracy: 0.2319\n",
      "Epoch 115/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 3316373211.8343 - accuracy: 0.2527 - val_loss: 441717888.0000 - val_accuracy: 0.2331\n",
      "Epoch 116/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 2073994603.0963 - accuracy: 0.2495 - val_loss: 945960576.0000 - val_accuracy: 0.2506\n",
      "Epoch 117/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3180218231.4138 - accuracy: 0.2419 - val_loss: 1215035008.0000 - val_accuracy: 0.2550\n",
      "Epoch 118/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 9745064910.6220 - accuracy: 0.2487 - val_loss: 528676736.0000 - val_accuracy: 0.2562\n",
      "Epoch 119/150\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 5560180386.9873 - accuracy: 0.2446 - val_loss: 6730369536.0000 - val_accuracy: 0.2525\n",
      "Epoch 120/150\n",
      "200/200 [==============================] - 64s 319ms/step - loss: 50925840908.7363 - accuracy: 0.2466 - val_loss: 19357474816.0000 - val_accuracy: 0.2556\n",
      "Epoch 121/150\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 34178916641.7199 - accuracy: 0.2486 - val_loss: 47050.6719 - val_accuracy: 0.2331\n",
      "Epoch 122/150\n",
      "200/200 [==============================] - 66s 331ms/step - loss: 19091078561.2895 - accuracy: 0.2546 - val_loss: 31911819264.0000 - val_accuracy: 0.2550\n",
      "Epoch 123/150\n",
      "200/200 [==============================] - 66s 333ms/step - loss: 62668821110.9913 - accuracy: 0.2490 - val_loss: 21837944832.0000 - val_accuracy: 0.2625\n",
      "Epoch 124/150\n",
      "200/200 [==============================] - 60s 299ms/step - loss: 81025365650.2583 - accuracy: 0.2458 - val_loss: 23868256256.0000 - val_accuracy: 0.2562\n",
      "Epoch 125/150\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 171869717226.1076 - accuracy: 0.2416 - val_loss: 137157599232.0000 - val_accuracy: 0.2506\n",
      "Epoch 126/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 14082189371.7956 - accuracy: 0.2613 - val_loss: 104407384064.0000 - val_accuracy: 0.2556\n",
      "Epoch 127/150\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 75393651064.4200 - accuracy: 0.2478 - val_loss: 226076459008.0000 - val_accuracy: 0.2612\n",
      "Epoch 128/150\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 654671497915.4727 - accuracy: 0.2567 - val_loss: 380021899264.0000 - val_accuracy: 0.2325\n",
      "Epoch 129/150\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 1334003965751.9639 - accuracy: 0.2385 - val_loss: 1517023526912.0000 - val_accuracy: 0.2550\n",
      "Epoch 130/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 3656634394981.3496 - accuracy: 0.2577 - val_loss: 2251987877888.0000 - val_accuracy: 0.2550\n",
      "Epoch 131/150\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 1972223458685.4390 - accuracy: 0.2534 - val_loss: 807988363264.0000 - val_accuracy: 0.2612\n",
      "Epoch 132/150\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 2903965373880.9243 - accuracy: 0.2482 - val_loss: 1288365146112.0000 - val_accuracy: 0.2500\n",
      "Epoch 133/150\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 6741882624101.1279 - accuracy: 0.2538 - val_loss: 6663992508416.0000 - val_accuracy: 0.2612\n",
      "Epoch 134/150\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 21441616998458.2383 - accuracy: 0.2471 - val_loss: 4163276898304.0000 - val_accuracy: 0.2625\n",
      "Epoch 135/150\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 17133464965503.0254 - accuracy: 0.2464 - val_loss: 10781257105408.0000 - val_accuracy: 0.2506\n",
      "Epoch 136/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 17076600018028.2637 - accuracy: 0.2344 - val_loss: 8628325056512.0000 - val_accuracy: 0.2325\n",
      "Epoch 137/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 14049410640478.3477 - accuracy: 0.2523 - val_loss: 26167862099968.0000 - val_accuracy: 0.2494\n",
      "Epoch 138/150\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 32296438918149.2539 - accuracy: 0.2598 - val_loss: 76893386702848.0000 - val_accuracy: 0.2506\n",
      "Epoch 139/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 128125409882564.3125 - accuracy: 0.2484 - val_loss: 177890146648064.0000 - val_accuracy: 0.2494\n",
      "Epoch 140/150\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 314052016861240.3125 - accuracy: 0.2541 - val_loss: 40672740507648.0000 - val_accuracy: 0.2338\n",
      "Epoch 141/150\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 343961995917067.0000 - accuracy: 0.2439 - val_loss: 290692379181056.0000 - val_accuracy: 0.2500\n",
      "Epoch 142/150\n",
      "200/200 [==============================] - 67s 335ms/step - loss: 504963209179313.9375 - accuracy: 0.2598 - val_loss: 431090766446592.0000 - val_accuracy: 0.2331\n",
      "Epoch 143/150\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 838142521173311.8750 - accuracy: 0.2571 - val_loss: 587409389518848.0000 - val_accuracy: 0.2481\n",
      "Epoch 144/150\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 912391133443715.5000 - accuracy: 0.2630 - val_loss: 735284979302400.0000 - val_accuracy: 0.2506\n",
      "Epoch 145/150\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 2797196321944785.0000 - accuracy: 0.2492 - val_loss: 1042073822167040.0000 - val_accuracy: 0.2619\n",
      "Epoch 146/150\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 1678106740565526.2500 - accuracy: 0.2544 - val_loss: 366371145777152.0000 - val_accuracy: 0.2556\n",
      "Epoch 147/150\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 6307137709309523.0000 - accuracy: 0.2465 - val_loss: 8290476587220992.0000 - val_accuracy: 0.2494\n",
      "Epoch 148/150\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 5706590181663918.0000 - accuracy: 0.2615 - val_loss: 2069159550648320.0000 - val_accuracy: 0.2494\n",
      "Epoch 149/150\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 4403713131452395.0000 - accuracy: 0.2551 - val_loss: 20035195654635520.0000 - val_accuracy: 0.2494\n",
      "Epoch 150/150\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 23115922609968072.0000 - accuracy: 0.2544 - val_loss: 13737873803051008.0000 - val_accuracy: 0.2338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9cc6274f0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "epochs=150\n",
    "model.fit(train_ds, epochs=epochs, validation_data=valid_ds, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34c880-5ba2-443e-8ef9-2709fbd11909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "# Vẽ đồ thị learning rate và loss:\n",
    "history = model.history\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-8, 1e-1, 0, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d0916-7d8a-40ec-bc01-a1e0e2a8f743",
   "metadata": {},
   "source": [
    "#### Train và valid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839b427-9a4f-49be-986c-71f6f42383dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 64)           640000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 666,216\n",
      "Trainable params: 666,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Xóa thông tin các model cũ:\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Tạo input:\n",
    "inputs = keras.Input(shape=(250))\n",
    "\n",
    "# Tạo embeding:\n",
    "embedding_dim = 64\n",
    "embeding = keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n",
    "\n",
    "# Tạo Bidirectional LSTM:\n",
    "lstm = keras.layers.Bidirectional(keras.layers.LSTM(32))(embeding)\n",
    "\n",
    "# Tạo dropout:\n",
    "dropout = keras.layers.Dropout(0.2)(lstm)\n",
    "\n",
    "# Tạo dense:\n",
    "dense = keras.layers.Dense(20, activation='relu')(dropout)\n",
    "\n",
    "# Tạo prediction:\n",
    "prediction = keras.layers.Dense(4, activation='softmax')(dense)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=prediction)\n",
    "\n",
    "# Tạo loss:\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Tạo optimizer:\n",
    "learning_rate=5e-4\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile model:\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0de801-1386-4bbd-938c-d2ca93b6f788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 77s 344ms/step - loss: 1.3595 - accuracy: 0.2993 - val_loss: 1.1762 - val_accuracy: 0.4225\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 65s 326ms/step - loss: 1.1484 - accuracy: 0.4799 - val_loss: 0.9325 - val_accuracy: 0.5788\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 0.8062 - accuracy: 0.6370 - val_loss: 0.7960 - val_accuracy: 0.6325\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 0.6100 - accuracy: 0.7130 - val_loss: 0.7775 - val_accuracy: 0.6369\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 68s 339ms/step - loss: 0.5270 - accuracy: 0.7518 - val_loss: 0.7661 - val_accuracy: 0.6531\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 66s 329ms/step - loss: 0.4556 - accuracy: 0.7700 - val_loss: 0.8027 - val_accuracy: 0.6662\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 60s 300ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.8515 - val_accuracy: 0.6675\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.3638 - accuracy: 0.8242 - val_loss: 0.8536 - val_accuracy: 0.6737\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.3269 - accuracy: 0.8494 - val_loss: 0.9267 - val_accuracy: 0.6831\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.2904 - accuracy: 0.8828 - val_loss: 0.9893 - val_accuracy: 0.6925\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 51s 253ms/step - loss: 0.2497 - accuracy: 0.9101 - val_loss: 1.1175 - val_accuracy: 0.6988\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 52s 262ms/step - loss: 0.1677 - accuracy: 0.9417 - val_loss: 1.2315 - val_accuracy: 0.7044\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 57s 284ms/step - loss: 0.1951 - accuracy: 0.9420 - val_loss: 1.2484 - val_accuracy: 0.7212\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 0.1530 - accuracy: 0.9470 - val_loss: 1.1901 - val_accuracy: 0.7194\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 66s 332ms/step - loss: 0.0929 - accuracy: 0.9735 - val_loss: 1.2777 - val_accuracy: 0.7256\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 0.0601 - accuracy: 0.9860 - val_loss: 1.4334 - val_accuracy: 0.7294\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 0.0462 - accuracy: 0.9889 - val_loss: 1.4842 - val_accuracy: 0.7344\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.0427 - accuracy: 0.9882 - val_loss: 1.4963 - val_accuracy: 0.7169\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.0375 - accuracy: 0.9901 - val_loss: 1.5213 - val_accuracy: 0.7281\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 0.0481 - accuracy: 0.9860 - val_loss: 1.3775 - val_accuracy: 0.7250\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 0.2058 - accuracy: 0.9410 - val_loss: 1.1940 - val_accuracy: 0.7169\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.1127 - accuracy: 0.9658 - val_loss: 1.2192 - val_accuracy: 0.7119\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.0555 - accuracy: 0.9859 - val_loss: 1.4028 - val_accuracy: 0.7219\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 0.0852 - accuracy: 0.9783 - val_loss: 1.4403 - val_accuracy: 0.7269\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 67s 334ms/step - loss: 0.0266 - accuracy: 0.9961 - val_loss: 1.4443 - val_accuracy: 0.7369\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 68s 340ms/step - loss: 0.0176 - accuracy: 0.9968 - val_loss: 1.5402 - val_accuracy: 0.7331\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 0.0442 - accuracy: 0.9903 - val_loss: 1.4831 - val_accuracy: 0.7312\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 61s 303ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 1.5520 - val_accuracy: 0.7356\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 54s 271ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 1.6474 - val_accuracy: 0.7375\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 1.8253 - val_accuracy: 0.6775\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 53s 265ms/step - loss: 0.0956 - accuracy: 0.9681 - val_loss: 1.7079 - val_accuracy: 0.7362\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 51s 256ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.7961 - val_accuracy: 0.7356\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 1.4457 - val_accuracy: 0.6569\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 69s 347ms/step - loss: 0.1617 - accuracy: 0.9437 - val_loss: 1.4008 - val_accuracy: 0.7113\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 73s 363ms/step - loss: 0.0373 - accuracy: 0.9881 - val_loss: 1.5810 - val_accuracy: 0.7244\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 68s 338ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 1.6946 - val_accuracy: 0.7244\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 67s 336ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 1.7588 - val_accuracy: 0.7337\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 59s 293ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 1.8237 - val_accuracy: 0.7131\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 51s 254ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.8344 - val_accuracy: 0.7319\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 51s 255ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 1.9297 - val_accuracy: 0.7344\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0207 - val_accuracy: 0.7350\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 52s 258ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 2.2046 - val_accuracy: 0.7069\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 50s 252ms/step - loss: 0.0430 - accuracy: 0.9925 - val_loss: 1.8180 - val_accuracy: 0.7150\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 63s 317ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 2.1641 - val_accuracy: 0.7119\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 67s 333ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 2.2248 - val_accuracy: 0.7031\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 71s 355ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 1.8762 - val_accuracy: 0.7231\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 71s 355ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 1.9510 - val_accuracy: 0.7200\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 64s 318ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 1.9886 - val_accuracy: 0.7350\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.0877 - val_accuracy: 0.7387\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 52s 260ms/step - loss: 7.6019e-04 - accuracy: 1.0000 - val_loss: 2.1562 - val_accuracy: 0.7412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4832873760>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "epochs=50\n",
    "model.fit(train_ds, epochs=epochs, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca3f6f-e1b2-4bdd-b2e1-e08fff88253b",
   "metadata": {},
   "source": [
    "**Lưu ý:**\n",
    "Kết quả này tương đối là tồi, mức độ overfit còn cao hơn so với việc chỉ sử dụng embedding layer, đây là điều dễ xảy ra vs LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e4dee-c564-44c3-97dc-e4abd56394de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
