# AUTOGENERATED BY NBDEV! DO NOT EDIT!

__all__ = ["index", "modules", "custom_doc_links", "git_url"]

index = {"path": "04_Basic_Text_Classification.ipynb",
         "url": "04_Basic_Text_Classification.ipynb",
         "dataset": "04_Basic_Text_Classification.ipynb",
         "remove_dir": "04_Basic_Text_Classification.ipynb",
         "train_ds": "04_Basic_Text_Classification.ipynb",
         "valid_ds": "04_Basic_Text_Classification.ipynb",
         "text_cleansing": "04_Basic_Text_Classification.ipynb",
         "max_features": "04_Basic_Text_Classification.ipynb",
         "sequence_length": "04_Basic_Text_Classification.ipynb",
         "vectorization_layer": "04_Basic_Text_Classification.ipynb",
         "vectorize_text": "04_Basic_Text_Classification.ipynb",
         "AUTOTUNE": "04_Basic_Text_Classification.ipynb",
         "embedding_dim": "01_Word_Embedding.ipynb",
         "model": "03_RNN_advanced.ipynb",
         "epochs": "04_Basic_Text_Classification.ipynb",
         "plot_history": "03_RNN_advanced.ipynb",
         "test_ds": "04_Basic_Text_Classification.ipynb",
         "exp_model": "04_Basic_Text_Classification.ipynb",
         "inference_data": "04_Basic_Text_Classification.ipynb",
         "bs": "04_Basic_Text_Classification.ipynb",
         "seed": "04_Basic_Text_Classification.ipynb",
         "raw_text": "04_Basic_Text_Classification.ipynb",
         "loss": "04_Basic_Text_Classification.ipynb",
         "optimizer": "04_Basic_Text_Classification.ipynb",
         "learning_rate": "04_Basic_Text_Classification.ipynb",
         "lr_scheduler": "04_Basic_Text_Classification.ipynb",
         "history": "01_Word_Embedding.ipynb",
         "file_name": "01_Word_Embedding.ipynb",
         "sentences": "01_Word_Embedding.ipynb",
         "labels": "01_Word_Embedding.ipynb",
         "num_words": "01_Word_Embedding.ipynb",
         "oov_tok": "01_Word_Embedding.ipynb",
         "train_size": "02_RNN.ipynb",
         "tokenizer": "03_RNN_advanced.ipynb",
         "train_sentences": "01_Word_Embedding.ipynb",
         "valid_sentences": "01_Word_Embedding.ipynb",
         "train_labels": "01_Word_Embedding.ipynb",
         "valid_labels": "01_Word_Embedding.ipynb",
         "word_index": "01_Word_Embedding.ipynb",
         "train_sequences": "01_Word_Embedding.ipynb",
         "valid_sequences": "01_Word_Embedding.ipynb",
         "max_len": "03_RNN_advanced.ipynb",
         "pad_type": "01_Word_Embedding.ipynb",
         "trunc_type": "01_Word_Embedding.ipynb",
         "embed_dim": "01_Word_Embedding.ipynb",
         "tokenizer_imdb": "02_RNN.ipynb",
         "BUFFER_SIZE": "02_RNN.ipynb",
         "BATCH_SIZE": "02_RNN.ipynb",
         "max_tokens": "04_Basic_Text_Classification.ipynb",
         "inputs": "04_Basic_Text_Classification.ipynb",
         "embeding": "04_Basic_Text_Classification.ipynb",
         "lstm": "04_Basic_Text_Classification.ipynb",
         "dropout": "04_Basic_Text_Classification.ipynb",
         "dense": "04_Basic_Text_Classification.ipynb",
         "prediction": "04_Basic_Text_Classification.ipynb",
         "vocab_size": "01_Word_Embedding.ipynb",
         "sequences": "01_Word_Embedding.ipynb",
         "padded_sequences": "03_RNN_advanced.ipynb",
         "padded_valid_sequences": "01_Word_Embedding.ipynb",
         "figure": "01_Word_Embedding.ipynb",
         "embedding": "01_Word_Embedding.ipynb",
         "embed_weights": "01_Word_Embedding.ipynb",
         "out_v": "01_Word_Embedding.ipynb",
         "out_m": "01_Word_Embedding.ipynb",
         "urls": "01_Word_Embedding.ipynb",
         "file": "01_Word_Embedding.ipynb",
         "padding_type": "01_Word_Embedding.ipynb",
         "oov_token": "01_Word_Embedding.ipynb",
         "training_size": "01_Word_Embedding.ipynb",
         "len_sentences": "01_Word_Embedding.ipynb",
         "len_dict": "01_Word_Embedding.ipynb",
         "n": "01_Word_Embedding.ipynb",
         "item_dict": "01_Word_Embedding.ipynb",
         "plot_list": "01_Word_Embedding.ipynb",
         "sarcasm_emb": "01_Word_Embedding.ipynb",
         "sarcasm_weights": "01_Word_Embedding.ipynb",
         "sarc_meta": "01_Word_Embedding.ipynb",
         "sarc_vect": "01_Word_Embedding.ipynb",
         "data": "03_RNN_advanced.ipynb",
         "corpus": "03_RNN_advanced.ipynb",
         "total_words": "03_RNN_advanced.ipynb",
         "input_sequences": "03_RNN_advanced.ipynb",
         "empty_dict": "03_RNN_advanced.ipynb",
         "ys": "03_RNN_advanced.ipynb",
         "seed_words": "03_RNN_advanced.ipynb",
         "next_words": "03_RNN_advanced.ipynb"}

modules = ["nlp/basic_text_classification.py",
           "nlp/rnn.py",
           "nlp/word_embedding.py",
           "nlp/advanced_rnn.py"]

doc_url = "https://ddpham.github.io/TFExam/"

git_url = "https://github.com/ddpham/TFExam/tree/{branch}/"

def custom_doc_links(name): return None
