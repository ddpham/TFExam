{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mục Đích\n",
    "> Trong phần này chúng ta sẽ cùng đi qua các phương thức để tạo được dataset của tensorflow, bao gồm:\n",
    "> 1. Load dữ liệu có sẵn của tensorflow_datasets\n",
    "> 2. Load dữ liệu từ folder\n",
    "> 3. Load dữ liệu từ file excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.4.1', '2.4.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA ONLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng keras datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'boston_housing',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'fashion_mnist',\n",
       " 'imdb',\n",
       " 'mnist',\n",
       " 'reuters']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kiểm tra dữ liệu:\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(X_train[i,:])\n",
    "    plt.title(y_train[i])\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biến đổi dữ liệu:\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93333333, 0.98823529, 0.98823529, 0.70196078, 0.04705882],\n",
       "       [0.99215686, 0.91372549, 0.81568627, 0.32941176, 0.        ],\n",
       "       [0.94117647, 0.27843137, 0.0745098 , 0.10980392, 0.        ],\n",
       "       [0.24705882, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kiểm tra dữ liệu sau khi chia cho 225 (giá trị sẽ từ 0 đến 1)\n",
    "X_train[1, 10:15, 10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]), TensorShape([10000, 28, 28]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize dữ liệu trước khi train, sử dụng mean và variance của imagenet:\n",
    "# https://forums.fast.ai/t/is-normalizing-the-input-image-by-imagenet-mean-and-std-really-necessary/51338\n",
    "normalizer = keras.layers.experimental.preprocessing.Normalization(mean=0.485, variance=0.229**2, name='normalize') \n",
    "X_train = normalizer(X_train)\n",
    "X_test = normalizer(X_test)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[ 1.9577874 ,  2.1975338 ,  2.1975338 ,  0.94742703, -1.9124069 ],\n",
       "       [ 2.2146587 ,  1.8721637 ,  1.4440448 , -0.67942464, -2.117904  ],\n",
       "       [ 1.9920369 , -0.9020464 , -1.7925336 , -1.6384109 , -2.117904  ],\n",
       "       [-1.0390445 , -2.117904  , -2.117904  , -2.117904  , -2.117904  ],\n",
       "       [-2.117904  , -2.117904  , -2.117904  , -2.117904  , -2.117904  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kiểm tra dữ liệu sau khi normalize:\n",
    "X_train[1, 10:15, 10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tạo neural net cơ bản:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo neural net cơ bản:\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28), name='flatten'),\n",
    "    keras.layers.Dense(128, activation='relu', name='layer1'),\n",
    "    keras.layers.Dropout(.2, name='dropout'),\n",
    "    keras.layers.Dense(20, activation='relu', name='layer2'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='predictions')\n",
    "])\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 103,270\n",
      "Trainable params: 103,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.7460 - accuracy: 0.7609 - val_loss: 0.2212 - val_accuracy: 0.9361\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2693 - accuracy: 0.9200 - val_loss: 0.1755 - val_accuracy: 0.9486\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2263 - accuracy: 0.9353 - val_loss: 0.1567 - val_accuracy: 0.9566\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2015 - accuracy: 0.9426 - val_loss: 0.1647 - val_accuracy: 0.9546\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1769 - accuracy: 0.9477 - val_loss: 0.1562 - val_accuracy: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f02733dc1f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đào tạo:\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lưu ý:** chúng ta sử dụng thêm normalizer để normalize dữ liệu thì kết quả metrics chưa thực sự rõ ràng, tuy nhiên loss được cải thiện tương đối."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thay đổi tốc độ học:\n",
    "> tốc độ học (learning rate) đi kèm với optimizer trong keras, nên muốn tác động vào lr, chúng ta có thể làm bằng 1 trong 2 cách sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Chọn optimizer bằng method trong keras.optimizers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate (tốc độ học) đi kèm với optimizer. Chúng ta có thể tác động vào learning rate với keras.optimizers:\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hoặc sử dụng keras backends để sửa learning rate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr before:  0.001\n",
      "lr after:  0.003\n"
     ]
    }
   ],
   "source": [
    "# Hoặc bằng cách sử dụng backend set_value method:\n",
    "print('lr before: ', model.optimizer.learning_rate.numpy())\n",
    "K.set_value(model.optimizer.learning_rate, 0.003)\n",
    "print('lr after: ', model.optimizer.learning_rate.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thay đổi hàm loss:\n",
    "> hàm loss (hàm mất mát) cũng có thể được thay đổi tương tự như learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BinaryCrossentropy',\n",
       " 'CategoricalCrossentropy',\n",
       " 'CategoricalHinge',\n",
       " 'CosineSimilarity',\n",
       " 'Hinge',\n",
       " 'Huber',\n",
       " 'KLD',\n",
       " 'KLDivergence',\n",
       " 'LogCosh',\n",
       " 'Loss',\n",
       " 'MAE',\n",
       " 'MAPE',\n",
       " 'MSE',\n",
       " 'MSLE',\n",
       " 'MeanAbsoluteError',\n",
       " 'MeanAbsolutePercentageError',\n",
       " 'MeanSquaredError',\n",
       " 'MeanSquaredLogarithmicError',\n",
       " 'Poisson',\n",
       " 'Reduction',\n",
       " 'SparseCategoricalCrossentropy',\n",
       " 'SquaredHinge',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'binary_crossentropy',\n",
       " 'categorical_crossentropy',\n",
       " 'categorical_hinge',\n",
       " 'cosine_similarity',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'hinge',\n",
       " 'huber',\n",
       " 'kl_divergence',\n",
       " 'kld',\n",
       " 'kullback_leibler_divergence',\n",
       " 'log_cosh',\n",
       " 'logcosh',\n",
       " 'mae',\n",
       " 'mape',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_logarithmic_error',\n",
       " 'mse',\n",
       " 'msle',\n",
       " 'poisson',\n",
       " 'serialize',\n",
       " 'sparse_categorical_crossentropy',\n",
       " 'squared_hinge']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo hàm loss:\n",
    "loss_func = keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss_func, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sửa hàm loss dùng backend.set_value:\n",
    "# print('loss func before: ', model.loss)\n",
    "# K.set_value(model.loss, keras.losses.categorical_crossentropy)\n",
    "# print('loss func after: ', model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 26s 13ms/step - loss: 0.9586 - accuracy: 0.7291 - val_loss: 0.2956 - val_accuracy: 0.9178\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.3808 - accuracy: 0.8878 - val_loss: 0.2168 - val_accuracy: 0.9347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4feb69a940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đào tạo lại\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)"
   ]
  },
  {
   "attachments": {
    "ad5ffac7-49af-4638-a6f3-f7a246d8f25c.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:ad5ffac7-49af-4638-a6f3-f7a246d8f25c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thay đổi metrics\n",
    "> Tương tự như lr và loss, chúng ta cũng có thể thay đổi metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUC',\n",
       " 'Accuracy',\n",
       " 'BinaryAccuracy',\n",
       " 'BinaryCrossentropy',\n",
       " 'CategoricalAccuracy',\n",
       " 'CategoricalCrossentropy',\n",
       " 'CategoricalHinge',\n",
       " 'CosineSimilarity',\n",
       " 'FalseNegatives',\n",
       " 'FalsePositives',\n",
       " 'Hinge',\n",
       " 'KLD',\n",
       " 'KLDivergence',\n",
       " 'LogCoshError',\n",
       " 'MAE',\n",
       " 'MAPE',\n",
       " 'MSE',\n",
       " 'MSLE',\n",
       " 'Mean',\n",
       " 'MeanAbsoluteError',\n",
       " 'MeanAbsolutePercentageError',\n",
       " 'MeanIoU',\n",
       " 'MeanRelativeError',\n",
       " 'MeanSquaredError',\n",
       " 'MeanSquaredLogarithmicError',\n",
       " 'MeanTensor',\n",
       " 'Metric',\n",
       " 'Poisson',\n",
       " 'Precision',\n",
       " 'PrecisionAtRecall',\n",
       " 'Recall',\n",
       " 'RecallAtPrecision',\n",
       " 'RootMeanSquaredError',\n",
       " 'SensitivityAtSpecificity',\n",
       " 'SparseCategoricalAccuracy',\n",
       " 'SparseCategoricalCrossentropy',\n",
       " 'SparseTopKCategoricalAccuracy',\n",
       " 'SpecificityAtSensitivity',\n",
       " 'SquaredHinge',\n",
       " 'Sum',\n",
       " 'TopKCategoricalAccuracy',\n",
       " 'TrueNegatives',\n",
       " 'TruePositives',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'binary_accuracy',\n",
       " 'binary_crossentropy',\n",
       " 'categorical_accuracy',\n",
       " 'categorical_crossentropy',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'hinge',\n",
       " 'kl_divergence',\n",
       " 'kld',\n",
       " 'kullback_leibler_divergence',\n",
       " 'log_cosh',\n",
       " 'logcosh',\n",
       " 'mae',\n",
       " 'mape',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_logarithmic_error',\n",
       " 'mse',\n",
       " 'msle',\n",
       " 'poisson',\n",
       " 'serialize',\n",
       " 'sparse_categorical_accuracy',\n",
       " 'sparse_categorical_crossentropy',\n",
       " 'sparse_top_k_categorical_accuracy',\n",
       " 'squared_hinge',\n",
       " 'top_k_categorical_accuracy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = keras.metrics.Precision()\n",
    "# recall = keras.metrics.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo hàm F1Score dự vào True Positive (TP), False Positive (FP) và False Negative (FN):\n",
    "# def f1(y_true, y_pred):\n",
    "#     # Tính True Positive:\n",
    "#     TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     # Tính Actual Positve: TP + FN\n",
    "#     TP_FN = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     # Tính Predicted Positve: TP + FP\n",
    "#     TP_FP = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     return  (2 * TP)/(TP_FN + TP_FP + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 103,270\n",
      "Trainable params: 103,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.3410 - accuracy: 0.9063 - val_loss: 0.2042 - val_accuracy: 0.9461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fe88803d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dữ liệu train và valid:\n",
    "train_ds, test_ds = tfds.load('mnist', split=['train', 'test'], shuffle_files=True, batch_size=32)\n",
    "# train_ds = tfds.load('mnist', split='train', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>\n",
      "<TakeDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra loại dữ liệu của train_ds/valid_ds:\n",
    "print(train_ds)\n",
    "print(train_ds.take(1)) # take method cho chúng ta lấy dữ liệu của tập train theo số lương iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops._OptionsDataset"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "dict_keys(['image', 'label'])\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "dict_keys(['image', 'label'])\n"
     ]
    }
   ],
   "source": [
    "# In index của iteration chúng ta lấy, và keys của images:\n",
    "for _, images in train_ds.take(2).enumerate():\n",
    "    print(_)\n",
    "    print(images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kiểm tra dữ liệu:\n",
    "plt.figure(figsize=(3, 3))\n",
    "for index, images in train_ds.take(1).enumerate():\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images['image'][i])\n",
    "#         plt.title(images['label'][i].numpy())\n",
    "        plt.title(np.int8(images['label'][i]))\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 93]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 81]\n",
      "  [252]\n",
      "  [253]\n",
      "  [150]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 32]\n",
      "  [247]\n",
      "  [253]\n",
      "  [183]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  1]\n",
      "  [109]\n",
      "  [237]\n",
      "  [253]\n",
      "  [253]\n",
      "  [249]\n",
      "  [  5]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [110]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [150]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [ 43]\n",
      "  [110]\n",
      "  [195]\n",
      "  [250]\n",
      "  [233]\n",
      "  [167]\n",
      "  [250]\n",
      "  [253]\n",
      "  [ 68]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[ 80]\n",
      "  [243]\n",
      "  [253]\n",
      "  [241]\n",
      "  [181]\n",
      "  [ 53]\n",
      "  [  7]\n",
      "  [244]\n",
      "  [253]\n",
      "  [ 43]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[ 69]\n",
      "  [199]\n",
      "  [130]\n",
      "  [ 20]\n",
      "  [  0]\n",
      "  [ 13]\n",
      "  [177]\n",
      "  [253]\n",
      "  [240]\n",
      "  [ 34]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 60]\n",
      "  [253]\n",
      "  [253]\n",
      "  [188]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 60]\n",
      "  [253]\n",
      "  [253]\n",
      "  [133]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [131]\n",
      "  [253]\n",
      "  [253]\n",
      "  [ 81]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [168]\n",
      "  [253]\n",
      "  [253]\n",
      "  [ 81]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 21]\n",
      "  [250]\n",
      "  [253]\n",
      "  [227]\n",
      "  [  4]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 96]\n",
      "  [253]\n",
      "  [253]\n",
      "  [152]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [130]\n",
      "  [253]\n",
      "  [253]\n",
      "  [ 75]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [130]\n",
      "  [253]\n",
      "  [253]\n",
      "  [ 10]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n"
     ]
    }
   ],
   "source": [
    "for index, images in train_ds.take(1).enumerate():\n",
    "    print(tf.slice(images['image'][1], [10, 10, 0], [15, 15, 1]).numpy())\n",
    "    if index > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_pixel(tensor):\n",
    "    tensor['image'] = tf.cast(tensor['image'], tf.float32)/255.\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function divide_pixel at 0x7fd724023c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function divide_pixel at 0x7fd724023c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function divide_pixel at 0x7fd724023c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(divide_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'cardinality',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'output_shapes',\n",
       " 'output_types',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tạo neural net cơ bản:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_trackable',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_autographed_call',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_arg_defaults',\n",
       " '_call_fn_arg_positions',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_cast_single_input',\n",
       " '_check_call_args',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_compile_was_called',\n",
       " '_compute_dtype',\n",
       " '_configure_steps_per_execution',\n",
       " '_dedup_weights',\n",
       " '_deferred_dependencies',\n",
       " '_dtype',\n",
       " '_eager_losses',\n",
       " '_flatten',\n",
       " '_flatten_layers',\n",
       " '_functional_construction_call',\n",
       " '_gather_children_attribute',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_get_call_arg_value',\n",
       " '_get_callback_model',\n",
       " '_get_compile_args',\n",
       " '_get_distribution_strategy',\n",
       " '_get_existing_metric',\n",
       " '_get_input_masks',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_optimizer',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_in_multi_worker_mode',\n",
       " '_inbound_nodes',\n",
       " '_infer_output_signature',\n",
       " '_init_batch_counters',\n",
       " '_init_call_fn_args',\n",
       " '_init_set_name',\n",
       " '_instrument_layer_creation',\n",
       " '_is_layer',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_keras_tensor_symbolic_call',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_epoch_from_ckpt',\n",
       " '_must_restore_from_config',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_no_dependency',\n",
       " '_obj_reference_counts',\n",
       " '_object_identifier',\n",
       " '_outbound_nodes',\n",
       " '_preload_simple_restoration',\n",
       " '_reset_compile_cache',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_set_call_arg_value',\n",
       " '_set_connectivity_metadata',\n",
       " '_set_dtype_policy',\n",
       " '_set_inputs',\n",
       " '_set_mask_keras_history_checked',\n",
       " '_set_mask_metadata',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_set_training_mode',\n",
       " '_setattr_tracking',\n",
       " '_should_cast_single_input',\n",
       " '_should_compute_mask',\n",
       " '_should_eval',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_split_out_first_arg',\n",
       " '_symbolic_call',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_undeduplicated_weights',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_validate_compile',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'build',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_dtype',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dtype_policy',\n",
       " 'dynamic',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'losses',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_shape',\n",
       " 'predict',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'run_eagerly',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variable_dtype',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.models.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten(input_shape=(28, 28, 1), name='flatten'))\n",
    "model.add(keras.layers.Dense(128, activation='relu', name='layer1'))\n",
    "model.add(keras.layers.Dropout(0.5, name='dropout'))\n",
    "model.add(keras.layers.Dense(20, activation='relu', name='layer2'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', name='prediction'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 103,270\n",
      "Trainable params: 103,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and loss_fuction\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "loss_func = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_func, metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractRNNCell',\n",
       " 'Activation',\n",
       " 'ActivityRegularization',\n",
       " 'Add',\n",
       " 'AdditiveAttention',\n",
       " 'AlphaDropout',\n",
       " 'Attention',\n",
       " 'Average',\n",
       " 'AveragePooling1D',\n",
       " 'AveragePooling2D',\n",
       " 'AveragePooling3D',\n",
       " 'AvgPool1D',\n",
       " 'AvgPool2D',\n",
       " 'AvgPool3D',\n",
       " 'BatchNormalization',\n",
       " 'Bidirectional',\n",
       " 'Concatenate',\n",
       " 'Conv1D',\n",
       " 'Conv1DTranspose',\n",
       " 'Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Conv3D',\n",
       " 'Conv3DTranspose',\n",
       " 'ConvLSTM2D',\n",
       " 'Convolution1D',\n",
       " 'Convolution1DTranspose',\n",
       " 'Convolution2D',\n",
       " 'Convolution2DTranspose',\n",
       " 'Convolution3D',\n",
       " 'Convolution3DTranspose',\n",
       " 'Cropping1D',\n",
       " 'Cropping2D',\n",
       " 'Cropping3D',\n",
       " 'Dense',\n",
       " 'DenseFeatures',\n",
       " 'DepthwiseConv2D',\n",
       " 'Dot',\n",
       " 'Dropout',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'Flatten',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GaussianDropout',\n",
       " 'GaussianNoise',\n",
       " 'GlobalAveragePooling1D',\n",
       " 'GlobalAveragePooling2D',\n",
       " 'GlobalAveragePooling3D',\n",
       " 'GlobalAvgPool1D',\n",
       " 'GlobalAvgPool2D',\n",
       " 'GlobalAvgPool3D',\n",
       " 'GlobalMaxPool1D',\n",
       " 'GlobalMaxPool2D',\n",
       " 'GlobalMaxPool3D',\n",
       " 'GlobalMaxPooling1D',\n",
       " 'GlobalMaxPooling2D',\n",
       " 'GlobalMaxPooling3D',\n",
       " 'Input',\n",
       " 'InputLayer',\n",
       " 'InputSpec',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'Lambda',\n",
       " 'Layer',\n",
       " 'LayerNormalization',\n",
       " 'LeakyReLU',\n",
       " 'LocallyConnected1D',\n",
       " 'LocallyConnected2D',\n",
       " 'Masking',\n",
       " 'MaxPool1D',\n",
       " 'MaxPool2D',\n",
       " 'MaxPool3D',\n",
       " 'MaxPooling1D',\n",
       " 'MaxPooling2D',\n",
       " 'MaxPooling3D',\n",
       " 'Maximum',\n",
       " 'Minimum',\n",
       " 'MultiHeadAttention',\n",
       " 'Multiply',\n",
       " 'PReLU',\n",
       " 'Permute',\n",
       " 'RNN',\n",
       " 'ReLU',\n",
       " 'RepeatVector',\n",
       " 'Reshape',\n",
       " 'SeparableConv1D',\n",
       " 'SeparableConv2D',\n",
       " 'SeparableConvolution1D',\n",
       " 'SeparableConvolution2D',\n",
       " 'SimpleRNN',\n",
       " 'SimpleRNNCell',\n",
       " 'Softmax',\n",
       " 'SpatialDropout1D',\n",
       " 'SpatialDropout2D',\n",
       " 'SpatialDropout3D',\n",
       " 'StackedRNNCells',\n",
       " 'Subtract',\n",
       " 'ThresholdedReLU',\n",
       " 'TimeDistributed',\n",
       " 'UpSampling1D',\n",
       " 'UpSampling2D',\n",
       " 'UpSampling3D',\n",
       " 'Wrapper',\n",
       " 'ZeroPadding1D',\n",
       " 'ZeroPadding2D',\n",
       " 'ZeroPadding3D',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'add',\n",
       " 'average',\n",
       " 'concatenate',\n",
       " 'deserialize',\n",
       " 'dot',\n",
       " 'experimental',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'serialize',\n",
       " 'subtract']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9436 - accuracy: 0.7031\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6678 - accuracy: 0.7031\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6774 - accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5289 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5682 - accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6875 - accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7721 - accuracy: 0.7031\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6233 - accuracy: 0.7812\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4480 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5187 - accuracy: 0.7969\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1820 - accuracy: 0.6719\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8849 - accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7749 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7819 - accuracy: 0.6875\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6402 - accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6482 - accuracy: 0.7656\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4617 - accuracy: 0.8125\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5211 - accuracy: 0.7812\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5205 - accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5489 - accuracy: 0.8125\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1843 - accuracy: 0.6406\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8074 - accuracy: 0.7188\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.9119 - accuracy: 0.7188\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8339 - accuracy: 0.7188\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8841 - accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5090 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5452 - accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4986 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6025 - accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7483 - accuracy: 0.7812\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6262 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5698 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5752 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5267 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3623 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3710 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3903 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2924 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1943 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3924 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2341 - accuracy: 0.5781\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6500 - accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5363 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7337 - accuracy: 0.7344\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4795 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4548 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4305 - accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5025 - accuracy: 0.7969\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5258 - accuracy: 0.7969\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5361 - accuracy: 0.8438\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5560 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4727 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4852 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5596 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3871 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2815 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2961 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1974 - accuracy: 0.9688\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2103 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2997 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8001 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6056 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4439 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4752 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4901 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4400 - accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4771 - accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4937 - accuracy: 0.8125\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3508 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2984 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7091 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5461 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6134 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4219 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3421 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3630 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1803 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4433 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2391 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2157 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5712 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3327 - accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4000 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3771 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3528 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2398 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3033 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1667 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4306 - accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2356 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0675 - accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6258 - accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5712 - accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6191 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3967 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3043 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4674 - accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3129 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2947 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3503 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7544 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5833 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5842 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3642 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6141 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4694 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2538 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3522 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3600 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2633 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7413 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7601 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5381 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6750 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5915 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6096 - accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4566 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4247 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5519 - accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2821 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0179 - accuracy: 0.7344\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8948 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7670 - accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5893 - accuracy: 0.7969\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5361 - accuracy: 0.8125\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6526 - accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5683 - accuracy: 0.7656\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4469 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5608 - accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3414 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8349 - accuracy: 0.7344\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7695 - accuracy: 0.7344\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5183 - accuracy: 0.7969\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5712 - accuracy: 0.7969\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6661 - accuracy: 0.7969\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5486 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6040 - accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3441 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3556 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.7812\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7833 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7586 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6746 - accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5640 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4825 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5869 - accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2993 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5045 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2399 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7291 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6445 - accuracy: 0.8281\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6096 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4875 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6370 - accuracy: 0.8125\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5839 - accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4299 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4451 - accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3677 - accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3177 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9703 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2478 - accuracy: 0.7031\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8399 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5950 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5669 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5439 - accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2852 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2386 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3840 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4578 - accuracy: 0.8594\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9139 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5942 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5297 - accuracy: 0.7969\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3971 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4678 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3637 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3961 - accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4060 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3031 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1056 - accuracy: 0.9844\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0614 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9514 - accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8795 - accuracy: 0.7656\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5833 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7113 - accuracy: 0.7969\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4848 - accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4490 - accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6177 - accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5807 - accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5730 - accuracy: 0.8125\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9196 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5435 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5932 - accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6809 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5667 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4122 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4220 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3551 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2369 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2388 - accuracy: 0.9531\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7427 - accuracy: 0.6875\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4380 - accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4878 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5103 - accuracy: 0.7969\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4732 - accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2803 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3417 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3664 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2189 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0788 - accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7273 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7110 - accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5569 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3890 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4315 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5516 - accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3509 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5759 - accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3765 - accuracy: 0.8594\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7346 - accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6491 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6121 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4587 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4992 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3757 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4110 - accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3616 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2668 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2701 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8570 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9321 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6724 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6365 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5314 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5061 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4641 - accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3739 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4318 - accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4684 - accuracy: 0.8281\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7433 - accuracy: 0.8281\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5756 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4252 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3763 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2426 - accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3366 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2846 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3180 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3955 - accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2333 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0414 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0133 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8797 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6504 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3428 - accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5721 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4475 - accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4349 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2783 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3458 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9703 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6583 - accuracy: 0.8281\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4480 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4848 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3660 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3401 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4037 - accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5125 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3466 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3788 - accuracy: 0.8438\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9701 - accuracy: 0.7344\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7930 - accuracy: 0.7031\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5814 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4389 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3163 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4878 - accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3199 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3270 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4315 - accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3199 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8368 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5664 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5464 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5642 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5579 - accuracy: 0.7969\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4649 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4244 - accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4340 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3847 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.4274 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0962 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6821 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5510 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5000 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5778 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6295 - accuracy: 0.7344\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3873 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4475 - accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5481 - accuracy: 0.8125\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0004 - accuracy: 0.7031\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5684 - accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4769 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5880 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4545 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2496 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4965 - accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3873 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3641 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2613 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9042 - accuracy: 0.6875\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6488 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5990 - accuracy: 0.7656\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6826 - accuracy: 0.7969\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6227 - accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5884 - accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4220 - accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4109 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2273 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3083 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5964 - accuracy: 0.8281\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5355 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6660 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4531 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4197 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3907 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3813 - accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3168 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3286 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3149 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8977 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5580 - accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5363 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4696 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3489 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4996 - accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3039 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3528 - accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2544 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8894 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7007 - accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5677 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6354 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6076 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2759 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3346 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3342 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3933 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4436 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8232 - accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.9271 - accuracy: 0.7344\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6065 - accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6071 - accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7326 - accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5991 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4711 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3663 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3780 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3071 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7038 - accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7551 - accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5137 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5977 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3229 - accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4217 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2987 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3488 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3290 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2288 - accuracy: 0.9375\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2853 - accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2437 - accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2266 - accuracy: 0.9219\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1838 - accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0744 - accuracy: 0.9688\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1832 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1012 - accuracy: 0.9531\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1471 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1435 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2160 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6294 - accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4857 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6397 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2849 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2719 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3701 - accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2667 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2417 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1540 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1880 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4668 - accuracy: 0.8281\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4075 - accuracy: 0.8281\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2321 - accuracy: 0.9219\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3508 - accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2979 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3877 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2953 - accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1226 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0950 - accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1751 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5999 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4299 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2426 - accuracy: 0.9219\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2264 - accuracy: 0.9531\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2009 - accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3352 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4472 - accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2140 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2409 - accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1247 - accuracy: 0.9531\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6962 - accuracy: 0.8594\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4057 - accuracy: 0.9219\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2556 - accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2797 - accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3387 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4196 - accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2547 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2465 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2979 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0897 - accuracy: 0.9844\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7051 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7584 - accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5200 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2874 - accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4153 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3422 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3154 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3035 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4985 - accuracy: 0.7969\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2199 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0496 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9055 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5656 - accuracy: 0.7656\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.6228 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6215 - accuracy: 0.7969\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5999 - accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3618 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5195 - accuracy: 0.7812\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6544 - accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3215 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8890 - accuracy: 0.7344\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7953 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7040 - accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5758 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6494 - accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6043 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4348 - accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4539 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3543 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4804 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6666 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5601 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4838 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4422 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4726 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2953 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2690 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2021 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3511 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2981 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8454 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7352 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6077 - accuracy: 0.7969\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5087 - accuracy: 0.8125\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4582 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3868 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3267 - accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3007 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5371 - accuracy: 0.7812\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3836 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7943 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5491 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4226 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5659 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3006 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2398 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3263 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1632 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2488 - accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3640 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9076 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6825 - accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4938 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4504 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5496 - accuracy: 0.8125\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4027 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2944 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4572 - accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3533 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3997 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1969 - accuracy: 0.7031\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8600 - accuracy: 0.6562\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6821 - accuracy: 0.7656\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4081 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4997 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4994 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3282 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3070 - accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3563 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4165 - accuracy: 0.8281\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0760 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7235 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4646 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4008 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4371 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3511 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3966 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4097 - accuracy: 0.8125\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2788 - accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3606 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7032 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7062 - accuracy: 0.7344\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6067 - accuracy: 0.7656\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4048 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3824 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5713 - accuracy: 0.7656\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4362 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3831 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3578 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2931 - accuracy: 0.8906\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6970 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5618 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4088 - accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2748 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3913 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2083 - accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3647 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3540 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2472 - accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2058 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6971 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4170 - accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6042 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3154 - accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3297 - accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1852 - accuracy: 0.9531\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2002 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2793 - accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2892 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8119 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6301 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4531 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2887 - accuracy: 0.9375\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3579 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2847 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2094 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2959 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2964 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2806 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4898 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2586 - accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3087 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1264 - accuracy: 0.9531\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1221 - accuracy: 0.9375\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0588 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1543 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1849 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0509 - accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1647 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8806 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3572 - accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4226 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3303 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1870 - accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3045 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3050 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2846 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2903 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2489 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8573 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4105 - accuracy: 0.8281\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3373 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1945 - accuracy: 0.9375\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3488 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3732 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3137 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3981 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1682 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3809 - accuracy: 0.8594\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6965 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4030 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4026 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4028 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5193 - accuracy: 0.7656\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3325 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3105 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2680 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4199 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2604 - accuracy: 0.8594\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8873 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5697 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3749 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4528 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1988 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2678 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2355 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3631 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2099 - accuracy: 0.9531\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3060 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5594 - accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6985 - accuracy: 0.7969\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6442 - accuracy: 0.7188\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4593 - accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4860 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3348 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3430 - accuracy: 0.8594\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4145 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6331 - accuracy: 0.8594\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4305 - accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3035 - accuracy: 0.8906\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3520 - accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1908 - accuracy: 0.9688\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2371 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2212 - accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2017 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1915 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1541 - accuracy: 0.9531\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1954 - accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.9239 - accuracy: 0.7344\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7190 - accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7500 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5012 - accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4663 - accuracy: 0.8281\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4831 - accuracy: 0.8125\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2431 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3143 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5121 - accuracy: 0.8125\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5306 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5703 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5158 - accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3922 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4151 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2135 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1990 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2434 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2377 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2958 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8050 - accuracy: 0.7656\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6990 - accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3547 - accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4067 - accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3974 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5308 - accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5498 - accuracy: 0.8125\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5018 - accuracy: 0.7969\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2874 - accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.90 - 0s 15ms/step - loss: 0.3297 - accuracy: 0.8750\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3968 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2854 - accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3423 - accuracy: 0.8906\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4471 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2925 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2133 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1277 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1433 - accuracy: 0.9688\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2469 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1796 - accuracy: 0.9375\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2805 - accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1989 - accuracy: 0.9375\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2071 - accuracy: 0.9375\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1660 - accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2074 - accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2029 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1958 - accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1684 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1487 - accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1561 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2761 - accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4601 - accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2305 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3037 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2395 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2453 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1699 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1577 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1944 - accuracy: 0.9219\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5713 - accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5713 - accuracy: 0.8281\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3201 - accuracy: 0.8906\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5300 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2079 - accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2114 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3208 - accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1599 - accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1104 - accuracy: 0.9688\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2157 - accuracy: 0.9688\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4068 - accuracy: 0.8594\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4006 - accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4031 - accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3746 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2268 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2032 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2068 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1190 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2037 - accuracy: 0.9375\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5842 - accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4561 - accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2451 - accuracy: 0.9375\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3359 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4115 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1617 - accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1013 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2942 - accuracy: 0.9219\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0884 - accuracy: 0.9688\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1208 - accuracy: 0.9375\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5119 - accuracy: 0.9219\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9337 - accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2875 - accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2344 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3085 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2494 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2386 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1775 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1630 - accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1358 - accuracy: 0.9688\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.9346 - accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5746 - accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3716 - accuracy: 0.8594\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3677 - accuracy: 0.8906\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3287 - accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3411 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2139 - accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6316 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2117 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1642 - accuracy: 0.9531\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1701 - accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5627 - accuracy: 0.81 - 0s 20ms/step - loss: 0.6319 - accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7269 - accuracy: 0.8281\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5350 - accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3269 - accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3449 - accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2955 - accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4882 - accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3013 - accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2178 - accuracy: 0.9062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.8231 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5470 - accuracy: 0.8438\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d430acb49536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "normalizer = keras.layers.experimental.preprocessing.Normalization(mean=0.485, variance=0.229**2, name='normalize')\n",
    "for _, images in train_ds.enumerate():\n",
    "    # divide to 255:\n",
    "    images['image'] = images['image']/255\n",
    "    images['image'] = normalizer(images['image'])\n",
    "    model.fit(images['image'], images['label'], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'cardinality',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'output_shapes',\n",
       " 'output_types',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Maps `map_func` across the elements of this dataset.\n",
       "\n",
       "This transformation applies `map_func` to each element of this dataset, and\n",
       "returns a new dataset containing the transformed elements, in the same\n",
       "order as they appeared in the input. `map_func` can be used to change both\n",
       "the values and the structure of a dataset's elements. For example, adding 1\n",
       "to each element, or projecting a subset of element components.\n",
       "\n",
       ">>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
       ">>> dataset = dataset.map(lambda x: x + 1)\n",
       ">>> list(dataset.as_numpy_iterator())\n",
       "[2, 3, 4, 5, 6]\n",
       "\n",
       "The input signature of `map_func` is determined by the structure of each\n",
       "element in this dataset.\n",
       "\n",
       ">>> dataset = Dataset.range(5)\n",
       ">>> # `map_func` takes a single argument of type `tf.Tensor` with the same\n",
       ">>> # shape and dtype.\n",
       ">>> result = dataset.map(lambda x: x + 1)\n",
       "\n",
       ">>> # Each element is a tuple containing two `tf.Tensor` objects.\n",
       ">>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\n",
       ">>> dataset = tf.data.Dataset.from_generator(\n",
       "...     lambda: elements, (tf.int32, tf.string))\n",
       ">>> # `map_func` takes two arguments of type `tf.Tensor`. This function\n",
       ">>> # projects out just the first component.\n",
       ">>> result = dataset.map(lambda x_int, y_str: x_int)\n",
       ">>> list(result.as_numpy_iterator())\n",
       "[1, 2, 3]\n",
       "\n",
       ">>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\n",
       ">>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
       "...               {\"a\": 2, \"b\": \"bar\"},\n",
       "...               {\"a\": 3, \"b\": \"baz\"}])\n",
       ">>> dataset = tf.data.Dataset.from_generator(\n",
       "...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
       ">>> # `map_func` takes a single argument of type `dict` with the same keys\n",
       ">>> # as the elements.\n",
       ">>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
       "\n",
       "The value or values returned by `map_func` determine the structure of each\n",
       "element in the returned dataset.\n",
       "\n",
       ">>> dataset = tf.data.Dataset.range(3)\n",
       ">>> # `map_func` returns two `tf.Tensor` objects.\n",
       ">>> def g(x):\n",
       "...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
       ">>> result = dataset.map(g)\n",
       ">>> result.element_spec\n",
       "(TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.string, name=None))\n",
       ">>> # Python primitives, lists, and NumPy arrays are implicitly converted to\n",
       ">>> # `tf.Tensor`.\n",
       ">>> def h(x):\n",
       "...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\n",
       ">>> result = dataset.map(h)\n",
       ">>> result.element_spec\n",
       "(TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, name=None))\n",
       ">>> # `map_func` can return nested structures.\n",
       ">>> def i(x):\n",
       "...   return (37.0, [42, 16]), \"foo\"\n",
       ">>> result = dataset.map(i)\n",
       ">>> result.element_spec\n",
       "((TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\n",
       " TensorSpec(shape=(), dtype=tf.string, name=None))\n",
       "\n",
       "`map_func` can accept as arguments and return any type of dataset element.\n",
       "\n",
       "Note that irrespective of the context in which `map_func` is defined (eager\n",
       "vs. graph), tf.data traces the function and executes it as a graph. To use\n",
       "Python code inside of the function you have a few options:\n",
       "\n",
       "1) Rely on AutoGraph to convert Python code into an equivalent graph\n",
       "computation. The downside of this approach is that AutoGraph can convert\n",
       "some but not all Python code.\n",
       "\n",
       "2) Use `tf.py_function`, which allows you to write arbitrary Python code but\n",
       "will generally result in worse performance than 1). For example:\n",
       "\n",
       ">>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
       ">>> # transform a string tensor to upper case string using a Python function\n",
       ">>> def upper_case_fn(t: tf.Tensor):\n",
       "...   return t.numpy().decode('utf-8').upper()\n",
       ">>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\n",
       "...           inp=[x], Tout=tf.string))\n",
       ">>> list(d.as_numpy_iterator())\n",
       "[b'HELLO', b'WORLD']\n",
       "\n",
       "3) Use `tf.numpy_function`, which also allows you to write arbitrary\n",
       "Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\n",
       "`tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\n",
       "For example:\n",
       "\n",
       ">>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
       ">>> def upper_case_fn(t: np.ndarray):\n",
       "...   return t.decode('utf-8').upper()\n",
       ">>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
       "...           inp=[x], Tout=tf.string))\n",
       ">>> list(d.as_numpy_iterator())\n",
       "[b'HELLO', b'WORLD']\n",
       "\n",
       "Note that the use of `tf.numpy_function` and `tf.py_function`\n",
       "in general precludes the possibility of executing user-defined\n",
       "transformations in parallel (because of Python GIL).\n",
       "\n",
       "Performance can often be improved by setting `num_parallel_calls` so that\n",
       "`map` will use multiple threads to process elements. If deterministic order\n",
       "isn't required, it can also improve performance to set\n",
       "`deterministic=False`.\n",
       "\n",
       ">>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
       ">>> dataset = dataset.map(lambda x: x + 1,\n",
       "...     num_parallel_calls=tf.data.AUTOTUNE,\n",
       "...     deterministic=False)\n",
       "\n",
       "Args:\n",
       "  map_func: A function mapping a dataset element to another dataset element.\n",
       "  num_parallel_calls: (Optional.) A `tf.int32` scalar `tf.Tensor`,\n",
       "    representing the number elements to process asynchronously in parallel.\n",
       "    If not specified, elements will be processed sequentially. If the value\n",
       "    `tf.data.AUTOTUNE` is used, then the number of parallel\n",
       "    calls is set dynamically based on available CPU.\n",
       "  deterministic: (Optional.) A boolean controlling whether determinism\n",
       "    should be traded for performance by allowing elements to be produced out\n",
       "    of order.  If `deterministic` is `None`, the\n",
       "    `tf.data.Options.experimental_deterministic` dataset option (`True` by\n",
       "    default) is used to decide whether to produce elements\n",
       "    deterministically.\n",
       "\n",
       "Returns:\n",
       "  Dataset: A `Dataset`.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tf.data.Dataset.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lưu ý:__ với tensorflow dataset, chúng ta muốn biến đổi dữ liệu cần áp dụng mapping với dữ liệu này, sử dụng phương pháp: `tf.data.Dataset.map`\n",
    "\n",
    "Ở đây, tương tự như bài toán của keras.dataset, chúng ta sẽ cần biến dữ liệu về khoảng 0-1 rồi normalize lại dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo hàm chia:\n",
    "def pixel_divide(tensor):\n",
    "    return ()tensor[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_graph_attr',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_input_dataset',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_func',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_options_attr',\n",
       " '_preload_simple_restoration',\n",
       " '_preserve_cardinality',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_transformation_name',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_use_inter_op_parallelism',\n",
       " '_variant_tensor',\n",
       " '_variant_tensor_attr',\n",
       " '_variant_tracker',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'cardinality',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'output_shapes',\n",
       " 'output_types',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x7f5cb122ae00>\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "The type specification of an element of this dataset.\n",
       "\n",
       ">>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
       ">>> dataset.element_spec\n",
       "TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
       "\n",
       "Returns:\n",
       "  A nested structure of `tf.TypeSpec` objects matching the structure of an\n",
       "  element of this dataset and specifying the type of individual components.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MapDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1e91c9022461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_divide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, transformation_func)\u001b[0m\n\u001b[1;32m   1994\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     \"\"\"\n\u001b[0;32m-> 1996\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m<ipython-input-12-d3c27b1d1be1>\u001b[0m in \u001b[0;36mpixel_divide\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tạo hàm chia:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpixel_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'MapDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.apply(pixel_divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [106]\n",
      "  [212]\n",
      "  [253]\n",
      "  [254]\n",
      "  [244]\n",
      "  [ 90]\n",
      "  [  7]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [ 51]\n",
      "  [247]\n",
      "  [253]\n",
      "  [253]\n",
      "  [254]\n",
      "  [253]\n",
      "  [253]\n",
      "  [169]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [239]\n",
      "  [222]\n",
      "  [118]\n",
      "  [ 60]\n",
      "  [214]\n",
      "  [254]\n",
      "  [254]\n",
      "  [151]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 21]\n",
      "  [ 13]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 13]\n",
      "  [161]\n",
      "  [253]\n",
      "  [222]\n",
      "  [ 80]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 30]\n",
      "  [213]\n",
      "  [254]\n",
      "  [228]\n",
      "  [ 21]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 59]\n",
      "  [254]\n",
      "  [253]\n",
      "  [113]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 26]\n",
      "  [255]\n",
      "  [254]\n",
      "  [ 80]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [110]\n",
      "  [254]\n",
      "  [227]\n",
      "  [ 21]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [104]\n",
      "  [240]\n",
      "  [254]\n",
      "  [156]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [134]\n",
      "  [240]\n",
      "  [253]\n",
      "  [169]\n",
      "  [  6]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[247]\n",
      "  [118]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 51]\n",
      "  [221]\n",
      "  [254]\n",
      "  [254]\n",
      "  [169]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[ 67]\n",
      "  [ 47]\n",
      "  [ 72]\n",
      "  [155]\n",
      "  [230]\n",
      "  [247]\n",
      "  [254]\n",
      "  [244]\n",
      "  [ 89]\n",
      "  [  6]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[253]\n",
      "  [253]\n",
      "  [254]\n",
      "  [253]\n",
      "  [253]\n",
      "  [236]\n",
      "  [171]\n",
      "  [ 46]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[253]\n",
      "  [253]\n",
      "  [254]\n",
      "  [168]\n",
      "  [ 85]\n",
      "  [ 19]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n"
     ]
    }
   ],
   "source": [
    "for index, images in train_ds.take(1).enumerate():\n",
    "    print(tf.slice(images['image'][1], [10, 10, 0], [15, 15, 1]).numpy())\n",
    "    if index > 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cách khác để có thể xem được hình ảnh:\n",
    "# train_ds, info = tfds.load('mnist', split='train', shuffle_files=True, with_info=True)\n",
    "# tfds.show_examples(train_ds, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một model đơn giản:\n",
    "model_tf = keras.Sequential([\n",
    "    keras.layers.Flatten(name='flatten', input_shape=(28, 28, 1)),\n",
    "    keras.layers.Dense(250, activation='relu', name='layer1'), \n",
    "    keras.layers.Dropout(.5, name='dropout')\n",
    "    keras.layers.Dense(10, activation='softmax', name='layer2')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='caterogical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 250)               196250    \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 198,760\n",
      "Trainable params: 198,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_OptionsDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-856230469917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '_OptionsDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, images in train_ds.enumerate():\n",
    "#     if index==0: \n",
    "#         ds_image = images['image']\n",
    "#         ds_label = images['label']\n",
    "#     ds_image = np.append(ds_image, images['image'])\n",
    "#     ds_label = np.append(ds_label, images['label'])\n",
    "# ds_image = tf.cast(np.reshape(ds_image, (-1, 28, 28, 1)), tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential_4 expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(28, 28, 1) dtype=uint8>, <tf.Tensor 'IteratorGetNext:1' shape=() dtype=int64>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a57f9e999a6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/ddpham/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer sequential_4 expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(28, 28, 1) dtype=uint8>, <tf.Tensor 'IteratorGetNext:1' shape=() dtype=int64>]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 12s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learn = keras.applications.resnet50.ResNet50(include_top=False)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (64, 28, 28, 1)\n",
      "Shape after:  (64, 28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vì train_ds là dạng 1 channel (28, 28, 1), nên để sử dụng pretrained models vs keras, chúng ta phải biến đổi tập train thành dữ liệu dạng 3 channels:\n",
    "for index, images in enumerate(train_ds.take(1)):\n",
    "    print('Shape before: ', images['image'].shape)\n",
    "    images['image'] = np.repeat(images['image'], 3, -1)\n",
    "    print('Shape after: ', images['image'].shape)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images['image'][i])\n",
    "        plt.title(images['label'][i].numpy())\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ResNet50',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'decode_predictions',\n",
       " 'preprocess_input']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(grayscale_batch.shape)  # (64, 224, 224)    \n",
    "# rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)    \n",
    "# print(rgb_batch.shape)  # (64, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "# Load dữ liệu train và valid:\n",
    "train_ds, valid_ds = tfds.load('mnist', split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "()\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "(4704,)\n",
      "(2,)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "(7056,)\n",
      "(3,)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "(9408,)\n",
      "(4,)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "(11760,)\n",
      "(5,)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "(14112,)\n",
      "(6,)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "(16464,)\n",
      "(7,)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "(18816,)\n",
      "(8,)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "(21168,)\n",
      "(9,)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "(23520,)\n",
      "(10,)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "(25872,)\n",
      "(11,)\n",
      "tf.Tensor(10, shape=(), dtype=int64)\n",
      "(28224,)\n",
      "(12,)\n",
      "tf.Tensor(11, shape=(), dtype=int64)\n",
      "(30576,)\n",
      "(13,)\n",
      "tf.Tensor(12, shape=(), dtype=int64)\n",
      "(32928,)\n",
      "(14,)\n",
      "tf.Tensor(13, shape=(), dtype=int64)\n",
      "(35280,)\n",
      "(15,)\n",
      "tf.Tensor(14, shape=(), dtype=int64)\n",
      "(37632,)\n",
      "(16,)\n",
      "tf.Tensor(15, shape=(), dtype=int64)\n",
      "(39984,)\n",
      "(17,)\n",
      "tf.Tensor(16, shape=(), dtype=int64)\n",
      "(42336,)\n",
      "(18,)\n",
      "tf.Tensor(17, shape=(), dtype=int64)\n",
      "(44688,)\n",
      "(19,)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n",
      "(47040,)\n",
      "(20,)\n",
      "tf.Tensor(19, shape=(), dtype=int64)\n",
      "(49392,)\n",
      "(21,)\n",
      "tf.Tensor(20, shape=(), dtype=int64)\n",
      "(51744,)\n",
      "(22,)\n",
      "tf.Tensor(21, shape=(), dtype=int64)\n",
      "(54096,)\n",
      "(23,)\n",
      "tf.Tensor(22, shape=(), dtype=int64)\n",
      "(56448,)\n",
      "(24,)\n",
      "tf.Tensor(23, shape=(), dtype=int64)\n",
      "(58800,)\n",
      "(25,)\n",
      "tf.Tensor(24, shape=(), dtype=int64)\n",
      "(61152,)\n",
      "(26,)\n",
      "tf.Tensor(25, shape=(), dtype=int64)\n",
      "(63504,)\n",
      "(27,)\n",
      "tf.Tensor(26, shape=(), dtype=int64)\n",
      "(65856,)\n",
      "(28,)\n",
      "tf.Tensor(27, shape=(), dtype=int64)\n",
      "(68208,)\n",
      "(29,)\n",
      "tf.Tensor(28, shape=(), dtype=int64)\n",
      "(70560,)\n",
      "(30,)\n",
      "tf.Tensor(29, shape=(), dtype=int64)\n",
      "(72912,)\n",
      "(31,)\n",
      "tf.Tensor(30, shape=(), dtype=int64)\n",
      "(75264,)\n",
      "(32,)\n",
      "tf.Tensor(31, shape=(), dtype=int64)\n",
      "(77616,)\n",
      "(33,)\n",
      "tf.Tensor(32, shape=(), dtype=int64)\n",
      "(79968,)\n",
      "(34,)\n",
      "tf.Tensor(33, shape=(), dtype=int64)\n",
      "(82320,)\n",
      "(35,)\n",
      "tf.Tensor(34, shape=(), dtype=int64)\n",
      "(84672,)\n",
      "(36,)\n",
      "tf.Tensor(35, shape=(), dtype=int64)\n",
      "(87024,)\n",
      "(37,)\n",
      "tf.Tensor(36, shape=(), dtype=int64)\n",
      "(89376,)\n",
      "(38,)\n",
      "tf.Tensor(37, shape=(), dtype=int64)\n",
      "(91728,)\n",
      "(39,)\n",
      "tf.Tensor(38, shape=(), dtype=int64)\n",
      "(94080,)\n",
      "(40,)\n",
      "tf.Tensor(39, shape=(), dtype=int64)\n",
      "(96432,)\n",
      "(41,)\n",
      "tf.Tensor(40, shape=(), dtype=int64)\n",
      "(98784,)\n",
      "(42,)\n",
      "tf.Tensor(41, shape=(), dtype=int64)\n",
      "(101136,)\n",
      "(43,)\n",
      "tf.Tensor(42, shape=(), dtype=int64)\n",
      "(103488,)\n",
      "(44,)\n",
      "tf.Tensor(43, shape=(), dtype=int64)\n",
      "(105840,)\n",
      "(45,)\n",
      "tf.Tensor(44, shape=(), dtype=int64)\n",
      "(108192,)\n",
      "(46,)\n",
      "tf.Tensor(45, shape=(), dtype=int64)\n",
      "(110544,)\n",
      "(47,)\n",
      "tf.Tensor(46, shape=(), dtype=int64)\n",
      "(112896,)\n",
      "(48,)\n",
      "tf.Tensor(47, shape=(), dtype=int64)\n",
      "(115248,)\n",
      "(49,)\n",
      "tf.Tensor(48, shape=(), dtype=int64)\n",
      "(117600,)\n",
      "(50,)\n",
      "tf.Tensor(49, shape=(), dtype=int64)\n",
      "(119952,)\n",
      "(51,)\n",
      "tf.Tensor(50, shape=(), dtype=int64)\n",
      "(122304,)\n",
      "(52,)\n",
      "tf.Tensor(51, shape=(), dtype=int64)\n",
      "(124656,)\n",
      "(53,)\n",
      "tf.Tensor(52, shape=(), dtype=int64)\n",
      "(127008,)\n",
      "(54,)\n",
      "tf.Tensor(53, shape=(), dtype=int64)\n",
      "(129360,)\n",
      "(55,)\n",
      "tf.Tensor(54, shape=(), dtype=int64)\n",
      "(131712,)\n",
      "(56,)\n",
      "tf.Tensor(55, shape=(), dtype=int64)\n",
      "(134064,)\n",
      "(57,)\n",
      "tf.Tensor(56, shape=(), dtype=int64)\n",
      "(136416,)\n",
      "(58,)\n",
      "tf.Tensor(57, shape=(), dtype=int64)\n",
      "(138768,)\n",
      "(59,)\n",
      "tf.Tensor(58, shape=(), dtype=int64)\n",
      "(141120,)\n",
      "(60,)\n",
      "tf.Tensor(59, shape=(), dtype=int64)\n",
      "(143472,)\n",
      "(61,)\n",
      "tf.Tensor(60, shape=(), dtype=int64)\n",
      "(145824,)\n",
      "(62,)\n",
      "tf.Tensor(61, shape=(), dtype=int64)\n",
      "(148176,)\n",
      "(63,)\n",
      "tf.Tensor(62, shape=(), dtype=int64)\n",
      "(150528,)\n",
      "(64,)\n",
      "tf.Tensor(63, shape=(), dtype=int64)\n",
      "(152880,)\n",
      "(65,)\n",
      "tf.Tensor(64, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for index, images in train_ds.enumerate():\n",
    "    if index.numpy() == 0: \n",
    "        train_images = np.repeat(images['image'][...], 3, -1)\n",
    "        train_labels = images['label'].numpy()\n",
    "    print(train_images.shape)\n",
    "    print(train_labels.shape)\n",
    "    print(index)\n",
    "    train_images = np.append(train_images, np.repeat(images['image'][...], 3, -1))\n",
    "    train_labels = np.append(train_labels, images['label'].numpy())\n",
    "    if index == 64: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.reshape(train_images, (-1, 28, 28, 3))\n",
    "train_images = tf.cast(train_images, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([66, 28, 28, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'cardinality',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'output_shapes',\n",
       " 'output_types',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [66,28,28,3] != values[1].shape = [66] [Op:Pack]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6720c9580657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_ds = tf.data.Dataset.from_tensor_slices(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \"\"\"\n\u001b[0;32m--> 691\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3153\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3156\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    127\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 129\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1523\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1459\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m   1460\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m-> 1461\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6378\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6379\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6380\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6382\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [66,28,28,3] != values[1].shape = [66] [Op:Pack]"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    [train_images, train_labels]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 32x32; got `input_shape=(28, 28, 3)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8b2157097ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tạo learner:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0m\u001b[1;32m    472\u001b[0m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;31m# Determine proper input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m   input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[1;32m    149\u001b[0m       \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    367\u001b[0m         if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    368\u001b[0m             (input_shape[1] is not None and input_shape[1] < min_size)):\n\u001b[0;32m--> 369\u001b[0;31m           raise ValueError('Input size must be at least ' + str(min_size) +\n\u001b[0m\u001b[1;32m    370\u001b[0m                            \u001b[0;34m'x'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'; got `input_shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                            str(input_shape) + '`')\n",
      "\u001b[0;31mValueError\u001b[0m: Input size must be at least 32x32; got `input_shape=(28, 28, 3)`"
     ]
    }
   ],
   "source": [
    "# Tạo learner:\n",
    "learn = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=(28, 28, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
