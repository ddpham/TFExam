# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/time_series/02_tseries_CNN.ipynb (unless otherwise specified).

__all__ = ['plot_series', 'create_trend', 'seasonal_pattern', 'create_seasonalities', 'create_noise', 'autocorrelation',
           'create_tfds', 'times', 'baseline', 'tseries', 'create_tfds_new', 'window_size', 'train_tfds', 'valid_tfds',
           'model', 'lr_schedule', 'optimizer', 'history', 'model', 'optimizer', 'plot_history', 'y_hat', 'y_hat',
           'y_hat', 'y_true', 'y_true', 'file_name', 'df', 'dtrain', 'dvalid', 'window_size', 'train_tfds',
           'valid_tfds', 'model', 'lr_scheduler', 'opitmizer', 'history', 'model', 'opitmizer', 'plot_history', 'y_hat',
           'y_hat', 'y_hat', 'y_true', 'y_true']

# Cell
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow_datasets as tfds
import numpy as np
import pandas as pd
import datetime as dt
import matplotlib.pyplot as plt

# Cell
def plot_series(time, series, format="-", start=0, end=None, label=None):
    plt.figure(figsize=(10, 6))
    plt.plot(time[start:end], series[start:end], format, label=label)
    plt.xlabel("Time")
    plt.ylabel("Value")
    if label:
        plt.legend(fontsize=14)
    plt.grid(True)
    plt.show()

# hàm tạo xu hướng: đơn giản là hàm của thời gian nhân với tỷ lệ slope (tanh):
def create_trend(times, slope=0):
    return times * slope

# Tạo xu tính chất vụ mùa:
def seasonal_pattern(season_time):
    return np.where(season_time < 0.4,
                    np.cos(season_time * 2 * np.pi),
                    1 / np.exp(3 * season_time))

# Tạo dữ liệu có vụ mùa:
def create_seasonalities(time, period, amplitude=1, phase=0):
    season_time = ((time + phase) % period) / period
    return amplitude * seasonal_pattern(season_time)

# Tạo nhiễu:
def create_noise(time, noise_level=1, seed=None):
    rnd = np.random.RandomState(seed) # tạo seed
    return rnd.randn(len(time)) * noise_level

# Tạo autocorrelation:
def autocorrelation(time, amplitude, seed=None):
    phi=0.8
    rnd = np.random.RandomState(seed)
    array = rnd.randn(len(time) + 1)
    for i in range(1, len(time) + 1):
        array[i] += phi * array[i-1]
    return array[1:] * amplitude

def create_tfds(series, window_size=5, batch_size=32, shuffle_size=1000):
    """
        series: dữ liệu đầu vào dưới dạng series (numpy array/range)
        window_size: size của từng window view dữ liệu, ví dụ 5:  5 điểm thời gian liên tiếp
        batch_size: size của 1 batch bao gồm nhiều window: ví dụ 32: 32 chuối 5 điểm thời gian, dùng để train dữ liệu theo batch
        shuffle_size: size của 1 lần shuffle vị trí của các window.
    """
    # Biến đổi series thành tensorflow dataset:
    dataset = tf.data.Dataset.from_tensor_slices(series)
    # Tạo window:
    dataset = dataset.window(window_size+1, shift=1, drop_remainder=True)
    # Trải phẳng:
    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))
    # Tạo Xs, y:
    dataset = dataset.map(lambda o: (o[:-1], o[-1]))
    # xáo dữ liệu:
    dataset = dataset.shuffle(buffer_size=shuffle_size)
    # Tạo batch:
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Cell
times = np.arange(4*365 + 1)
baseline = 50
tseries = baseline + create_trend(times, slope = 0.1)\
+ create_seasonalities(times, period=365, amplitude=100)\
+ create_noise(times, seed=42)\
+ autocorrelation(times, amplitude=15)
plot_series(times, tseries)

# Cell
def create_tfds_new(series, window_size=5, batch_size=32, shuffle_size=1000):
    """
        series: dữ liệu đầu vào dưới dạng series (numpy array/range)
        window_size: size của từng window view dữ liệu, ví dụ 5:  5 điểm thời gian liên tiếp
        batch_size: size của 1 batch bao gồm nhiều window: ví dụ 32: 32 chuối 5 điểm thời gian, dùng để train dữ liệu theo batch
        shuffle_size: size của 1 lần shuffle vị trí của các window.
    """
    # Tăng size cho dữ liệu:
    series = tf.expand_dims(series, axis=-1)

    # Biến đổi series thành tensorflow dataset:
    dataset = tf.data.Dataset.from_tensor_slices(series)
    # Tạo window:
    dataset = dataset.window(window_size+1, shift=1, drop_remainder=True)
    # Trải phẳng:
    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))
    # Tạo Xs, y:
    dataset = dataset.map(lambda o: (o[:-1], o[-1]))
    # xáo dữ liệu:
    dataset = dataset.shuffle(buffer_size=shuffle_size)
    # Tạo batch:
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Cell
# Tạo dữ liệu:
window_size = 20
train_tfds = create_tfds_new(tseries[:3*365], window_size=window_size)
valid_tfds = create_tfds_new(tseries[3*365:], window_size=window_size)

# Cell
keras.backend.clear_session()

# Cell
model = keras.Sequential()

# Tạo layer Convolutional:
model.add(keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=[None, 1]))

# Tạo các layers Recurrent:
model.add(keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True)))
model.add(keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True)))
model.add(keras.layers.Dense(1))
model.add(keras.layers.Lambda(lambda x: x * 100))

# Tạo lr scheduler:
lr_schedule = keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch/20))

# Tạo optimizer:
optimizer = keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9, nesterov=True)

model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mse'])
model.summary()

# Cell
model.fit(train_tfds, epochs=400, validation_data=valid_tfds, callbacks=[lr_schedule])

# Cell
# Vẽ đồ thị learning rate và loss:
history = model.history
plt.figure(figsize=(8,4))
plt.semilogx(history.history["lr"], history.history["loss"])
plt.axis([1e-8, 1e-1, 0, 50])
plt.show()

# Cell
keras.backend.clear_session()
# Tạo layer Convolutional:
model = keras.Sequential([
    keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=[None, 1])
    , keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True))
    , keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True))
    , keras.layers.Dense(1)
    , keras.layers.Lambda(lambda x: x * 100)
])
optimizer = keras.optimizers.SGD(learning_rate=5e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mse'])
model.summary()

# Cell
model.fit(train_tfds, epochs=400, validation_data=valid_tfds)

# Cell
def plot_history(history, metrics:str='Accuracy'):
    item_dict = {'Loss': ['loss', 'val_loss'], f'{metrics}': [f'{metrics.lower()}', f'val_{metrics.lower()}']}
    plot_list = ['Loss', f'{metrics}']
    plt.figure(figsize=(8, 4))
    for i in range(len(plot_list)):
        plt.subplot(1, 2, i+1)
        item = plot_list[i]
        for items in item_dict[item]:
            plt.plot(history.history[items])
        plt.legend(item_dict[item])
    plt.tight_layout()

# Cell
plot_history(model.history, metrics='mse')

# Cell
y_hat = model.predict(valid_tfds)

# Cell
y_hat = y_hat.mean(axis=1)
y_hat = y_hat.reshape((346,))

# Cell
y_true = []
for tfds in valid_tfds:
    y = tfds[1].numpy()
    for i in y:
        y_true.append(i[0])
y_true = np.array(y_true)
y_true.shape

# Cell
plt.figure(figsize=(10,6))
plt.plot(y_hat)
plt.plot(y_true)
plt.legend(['y_hat', 'y_true'])
plt.show()

# Cell
file_name = '~/git/TFExam/data//daily-minimum-temperatures-in-me.csv'

# Cell
# df = pd.read_csv(file_name, header=None, skiprows=1, names=['date', 'temperature'], dtype=[str, np.float64])
df = pd.read_csv(file_name)
df.info()

# Cell
# Đổi tên cột:
df.columns = ['date', 'temp']

# Cell
# Biến đổi dữ liệu
df.temp = df.temp.str.replace('?','')

# Cell
# Biến đổi temperature sang dạng float:
df.temp = df.temp.astype(np.float64)
df.date = pd.to_datetime(df.date)

# Cell
# Vẽ dữ liệu
df.plot(x='date', y='temp', figsize=(10,6))
plt.show()

# Cell
dtrain = df[df.date < '1990-01-01'].temp
dvalid = df[df.date >= '1990-01-01'].temp

# Cell
# Sử dụng window size là 1 tháng:
window_size = 30
train_tfds = create_tfds_new(dtrain, window_size=window_size)
valid_tfds = create_tfds_new(dvalid, window_size=window_size)

# Cell
keras.backend.clear_session()
model = keras.Sequential([
    keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=[None, 1])
    , keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True))
    , keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True))
    , keras.layers.Dense(1)
    , keras.layers.Lambda(lambda x: x * 10)
])
# Tạo lr scheduler:
lr_scheduler = keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch/20))
opitmizer = keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9, nesterov=True)
model.compile(optimizer=opitmizer, loss=keras.losses.Huber(), metrics=['mae', 'mse'])
model.summary()

# Cell
model.fit(train_tfds, epochs=200, validation_data=valid_tfds, callbacks=[lr_scheduler])

# Cell
## Vẽ đồ thị giữa learning rate và loss:
history = model.history
plt.semilogx(history.history['lr'], history.history['loss'])
plt.axis([1e-8, 1e-1, 0, 30])
plt.show()

# Cell
keras.backend.clear_session()
model = keras.Sequential([
    keras.layers.Conv1D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=[None, 1])
    , keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True))
    , keras.layers.Bidirectional(keras.layers.LSTM(window_size*2, return_sequences=True))
    , keras.layers.Dense(1)
    , keras.layers.Lambda(lambda x: x * 10)
])
opitmizer = keras.optimizers.SGD(learning_rate=5e-6, momentum=0.9, nesterov=True)
model.compile(optimizer=opitmizer, loss=keras.losses.Huber(), metrics=['mae', 'mse'])
model.summary()

# Cell
model.fit(train_tfds, epochs=200, validation_data=valid_tfds)

# Cell
def plot_history(history, metrics:str='Accuracy'):
    item_dict = {'Loss': ['loss', 'val_loss'], f'{metrics}': [f'{metrics.lower()}', f'val_{metrics.lower()}']}
    plot_list = ['Loss', f'{metrics}']
    plt.figure(figsize=(10, 6))
    for i in range(len(plot_list)):
        plt.subplot(1, 2, i+1)
        item = plot_list[i]
        for items in item_dict[item]:
            plt.plot(history.history[items])
        plt.legend(item_dict[item])
    plt.tight_layout()

# Cell
plot_history(model.history, metrics='mse')

# Cell
plot_history(model.history, metrics='mae')

# Cell
y_hat = model.predict(valid_tfds)
y_hat.shape

# Cell
# Chúng ta sẽ lấy giá trị mean của y_hat làm giá trị prediction:
y_hat = y_hat.mean(axis=1)
y_hat = y_hat.reshape((335,))
y_hat[:10]

# Cell
y_true = []
for tfds in valid_tfds:
    y = tfds[1].numpy()
    for i in y:
        y_true.append(i)
y_true = np.array(y_true)
y_true.shape

# Cell
plt.figure(figsize=(20,6))
plt.plot(y_hat)
plt.plot(y_true)
plt.legend(['y_hat', 'y_true'])
plt.show()