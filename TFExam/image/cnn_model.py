# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/image/02_image_CNN_model.ipynb (unless otherwise specified).

__all__ = ['path', 'bs', 'train_ds', 'valid_ds', 'model', 'optimizer', 'loss_func', 'epochs', 'visualized_outputs',
           'layer_names', 'visualized_model', 'get_sample_image', 'sample_image', 'feature_maps', 'bs', 'train_ds',
           'valid_ds', 'preprocessing_layer', 'preprocessing_image', 'train_ds', 'valid_ds', 'resnet', 'flatten',
           'prediction', 'model', 'model_sample', 'model_names', 'model_sample', 'sample_image', 'sample_features',
           'sample_image', 'sample_features']

# Cell
path = '/home/ddpham/git/TFExam/data/sw/'

# Cell
bs = 16
train_ds = preprocessing.image_dataset_from_directory(
    directory=f'{path}/train'
    , labels='inferred'
    , label_mode='binary'
    , batch_size=bs
    , image_size=(300, 300)
)
valid_ds = preprocessing.image_dataset_from_directory(
    directory=f'{path}/test'
    , labels='inferred'
    , label_mode='binary'
    , batch_size=bs
    , image_size=(300, 300)
)

# Cell
model = keras.Sequential([
    keras.layers.Conv2D(16, 3, activation='relu', input_shape=(300, 300, 3)) # filters=16, kernel size=3
    , keras.layers.MaxPooling2D(2, 2) # pooling size=2, strides=2
    , keras.layers.Conv2D(32, 3, activation='relu')
    , keras.layers.MaxPooling2D(2, 2)
    , keras.layers.Conv2D(64, 3, activation='relu')
    , keras.layers.MaxPooling2D(2, 2)
    , keras.layers.Conv2D(64, 3, activation='relu')
    , keras.layers.MaxPooling2D(2, 2)
    , keras.layers.Conv2D(64, 3, activation='relu')
    , keras.layers.MaxPooling2D(2, 2)
    , keras.layers.Flatten()
    , keras.layers.Dense(512, activation='relu')
    , keras.layers.Dense(1, activation='sigmoid')
])

# Cell
model.summary()

# Cell
optimizer = keras.optimizers.Adam(learning_rate=3e-4)
loss_func = keras.losses.BinaryCrossentropy()
model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])

# Cell
epochs=10
model.fit(train_ds, epochs=epochs, validation_data=valid_ds)

# Cell
# Chúng ta có 10 layers trong model trên cần xem kết quả đầu ra:
visualized_outputs = [layer.output for layer in model.layers[1:10]]

# Cell
# Lấy tên cho từng layer để tạo title ảnh:
layer_names = [layer.name for layer in model.layers[1:10]]
layer_names

# Cell
# Tạo model để lấy kết quả visualize:
visualized_model = keras.Model(inputs=model.input, outputs=visualized_outputs)

# Cell
visualized_model.summary()

# Cell
# Tạo function lấy dữ liệu sample:
def get_sample_image(valid_ds):
    i = 0
    for image, lable in valid_ds.take(1):
        j = np.random.randint(0, 16)
        sample_image = image[j]
        i +=1
        if i > 1: break
    return tf.expand_dims(sample_image, axis=0)

# Cell
# Lấy sample dữ liệu
sample_image = get_sample_image(valid_ds)

# Cell
# Tạo dữ liệu cho các layers:
feature_maps = visualized_model.predict(sample_image)

# Cell
for i, name, feature in zip(range(len(layer_names)), layer_names, feature_maps):
    n_features = feature.shape[-1]
    size = feature.shape[1]
    display_grid = np.zeros((size, size * n_features))
    for i in range(n_features):
        x = feature[0, :, :, i]
        x -= x.mean()
        x /= x.std()
        x *= 64
        x += 128
        x = np.clip(x, 0, 255).astype('uint8')
        display_grid[:, i * size: (i+1) * size] = x
    scale = 20./ n_features
    plt.figure(figsize=(scale * n_features, scale))
#     plt.figure(figsize=(30, 1))
    plt.title(name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')

# Cell
bs = 16
train_ds = preprocessing.image_dataset_from_directory(
    directory=f'{path}/train'
    , labels='inferred'
    , label_mode='binary'
    , batch_size=bs
    , image_size=(460, 460)
)
valid_ds = preprocessing.image_dataset_from_directory(
    directory=f'{path}/test'
    , labels='inferred'
    , label_mode='binary'
    , batch_size=bs
    , image_size=(460, 460)
)

# Cell
preprocessing_layer = keras.Sequential([
    keras.layers.experimental.preprocessing.RandomCrop(224, 224)
    , keras.layers.experimental.preprocessing.RandomFlip('vertical')
])

# Cell
def preprocessing_image(x, y):
    x = preprocessing_layer(x, training=True)
    x = keras.applications.resnet50.preprocess_input(x)
    return (x, y)

# Cell
train_ds = train_ds.map(preprocessing_image)
valid_ds = valid_ds.map(preprocessing_image)

# Cell
resnet = keras.applications.resnet50.ResNet50(include_top=False, input_shape=(224, 224, 3))
for layer in resnet.layers:
    layer.trainable=False

# Cell
flatten = keras.layers.Flatten(name='flatten')(resnet.output)
prediction = keras.layers.Dense(1, activation='sigmoid', name='prediction')(flatten)

# Cell
keras.backend.clear_session()
model = keras.Model(inputs=resnet.input, outputs=prediction)
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=3e-4),
    loss=keras.losses.BinaryCrossentropy(),
    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]
)
model.summary()

# Cell
model.fit(train_ds, epochs=10, validation_data=valid_ds)

# Cell
# Chọn 5 layers làm ví dụ:
model_sample = []
model_names = []
for i in range(15):
    model_sample.append(model.layers[i].output)
    model_names.append(model.layers[i].name)
model_sample = keras.Model(inputs=model.input, outputs=model_sample)
model_sample.summary()

# Cell
sample_image = get_sample_image(train_ds)
sample_features = model_sample.predict(sample_image)
for name, feature in zip(model_names, sample_features):
    n_features = feature.shape[-1]
    size = feature.shape[1]
    display_grid = np.zeros((size, size * n_features))
    for i in range(n_features):
        x = feature[0, :, :, i]
        x -= x.mean()
        x /= x.std()
        x *= 64
        x += 128
        x = np.clip(x, 0, 255).astype('uint8')
        display_grid[:, i * size: (i+1) * size] = x
    scale = 20./ n_features
    plt.figure(figsize=(scale * n_features, scale))
#     plt.figure(figsize=(30, 1))
    plt.title(name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')

# Cell
sample_image = get_sample_image(train_ds)
sample_features = model_sample.predict(sample_image)
for i, name, feature in zip(range(len(model_names)), model_names, sample_features):
    n_features = feature.shape[-1]
    size = feature.shape[1]
    display_grid = np.zeros((size, size * n_features))
    for i in range(n_features):
        x = feature[0, :, :, i]
        x -= x.mean()
        x /= x.std()
        x *= 64
        x += 128
        x = np.clip(x, 0, 255).astype('uint8')
        display_grid[:, i * size: (i+1) * size] = x
    scale = 20./ n_features
#     plt.figure(figsize=(scale * n_features, scale))
    plt.figure(figsize=(30, 6))
    plt.title(name)
    plt.grid(False)
#         plt.imshow(display_grid, aspect='auto', cmap='viridis')
    plt.imshow(display_grid[:, :400])